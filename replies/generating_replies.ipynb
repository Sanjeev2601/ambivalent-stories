{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d94c95db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting openai\n",
      "  Downloading openai-2.8.1-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting python-dotenv\n",
      "  Downloading python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.3.3-cp311-cp311-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m98.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tqdm\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tenacity\n",
      "  Downloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Collecting anyio<5,>=3.5.0\n",
      "  Downloading anyio-4.12.0-py3-none-any.whl (113 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.4/113.4 kB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting distro<2,>=1.7.0\n",
      "  Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Collecting httpx<1,>=0.23.0\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting jiter<1,>=0.10.0\n",
      "  Downloading jiter-0.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (364 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m364.6/364.6 kB\u001b[0m \u001b[31m60.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pydantic<3,>=1.9.0\n",
      "  Downloading pydantic-2.12.5-py3-none-any.whl (463 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m463.6/463.6 kB\u001b[0m \u001b[31m69.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting sniffio\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /home/ec2-user/.local/lib/python3.11/site-packages (from openai) (4.15.0)\n",
      "Collecting numpy>=1.23.2\n",
      "  Downloading numpy-2.3.5-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.9/16.9 MB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /home/ec2-user/.local/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.2/509.2 kB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tzdata>=2022.7\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.8/347.8 kB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting idna>=2.8\n",
      "  Downloading idna-3.11-py3-none-any.whl (71 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.0/71.0 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting certifi\n",
      "  Downloading certifi-2025.11.12-py3-none-any.whl (159 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.4/159.4 kB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting httpcore==1.*\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting h11>=0.16\n",
      "  Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Collecting annotated-types>=0.6.0\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Collecting pydantic-core==2.41.5\n",
      "  Downloading pydantic_core-2.41.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m75.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting typing-inspection>=0.4.2\n",
      "  Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/.local/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Installing collected packages: pytz, tzdata, typing-inspection, tqdm, tenacity, sniffio, python-dotenv, pydantic-core, numpy, jiter, idna, h11, distro, certifi, annotated-types, pydantic, pandas, httpcore, anyio, httpx, openai\n",
      "Successfully installed annotated-types-0.7.0 anyio-4.12.0 certifi-2025.11.12 distro-1.9.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 idna-3.11 jiter-0.12.0 numpy-2.3.5 openai-2.8.1 pandas-2.3.3 pydantic-2.12.5 pydantic-core-2.41.5 python-dotenv-1.2.1 pytz-2025.2 sniffio-1.3.1 tenacity-9.1.2 tqdm-4.67.1 typing-inspection-0.4.2 tzdata-2025.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade openai python-dotenv pandas tqdm tenacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b941154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97415c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type\n",
    "\n",
    "from openai import OpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e6818bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY loaded: YES\n"
     ]
    }
   ],
   "source": [
    "# Load the .env file\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "except Exception:\n",
    "    print(\"python-dotenv not installed or .env missing\")\n",
    "\n",
    "# Fetch the key\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "print(\"OPENAI_API_KEY loaded:\", \"YES\" if OPENAI_API_KEY else \"NO\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e67814bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key check successful ✔️\n"
     ]
    }
   ],
   "source": [
    "if not OPENAI_API_KEY:\n",
    "    raise ValueError(\"❌ API Key not found. Make sure it's in your .env file as OPENAI_API_KEY.\")\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "# Tiny check call\n",
    "try:\n",
    "    resp = client.responses.create(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        input=\"Hello! Just checking if the API key works.\"\n",
    "    )\n",
    "    print(\"API Key check successful ✔️\")\n",
    "except Exception as e:\n",
    "    print(\"❌ Key failed:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d21c328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_id</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>babbage-002</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chatgpt-4o-latest</td>\n",
       "      <td>Chat / Reasoning Models</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>codex-mini-latest</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dall-e-2</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dall-e-3</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>tts-1</td>\n",
       "      <td>Audio / Speech Models</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>tts-1-1106</td>\n",
       "      <td>Audio / Speech Models</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>tts-1-hd</td>\n",
       "      <td>Audio / Speech Models</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>tts-1-hd-1106</td>\n",
       "      <td>Audio / Speech Models</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>whisper-1</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              model_id                 category\n",
       "0          babbage-002                    Other\n",
       "1    chatgpt-4o-latest  Chat / Reasoning Models\n",
       "2    codex-mini-latest                    Other\n",
       "3             dall-e-2                    Other\n",
       "4             dall-e-3                    Other\n",
       "..                 ...                      ...\n",
       "97               tts-1    Audio / Speech Models\n",
       "98          tts-1-1106    Audio / Speech Models\n",
       "99            tts-1-hd    Audio / Speech Models\n",
       "100      tts-1-hd-1106    Audio / Speech Models\n",
       "101          whisper-1                    Other\n",
       "\n",
       "[102 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List all available OpenAI models with categories\n",
    "\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "models = client.models.list()\n",
    "\n",
    "model_data = []\n",
    "\n",
    "for m in models.data:\n",
    "    model_id = m.id\n",
    "\n",
    "    # Categorize based on name patterns\n",
    "    if \"gpt\" in model_id.lower() or \"o1\" in model_id.lower():\n",
    "        category = \"Chat / Reasoning Models\"\n",
    "    elif \"embed\" in model_id.lower():\n",
    "        category = \"Embedding Models\"\n",
    "    elif \"tts\" in model_id.lower() or \"audio\" in model_id.lower():\n",
    "        category = \"Audio / Speech Models\"\n",
    "    elif \"vision\" in model_id.lower() or \"clip\" in model_id.lower():\n",
    "        category = \"Vision Models\"\n",
    "    else:\n",
    "        category = \"Other\"\n",
    "\n",
    "    model_data.append({\n",
    "        \"model_id\": model_id,\n",
    "        \"category\": category\n",
    "    })\n",
    "\n",
    "df_models = pd.DataFrame(model_data).sort_values(\"model_id\")\n",
    "df_models.reset_index(drop=True, inplace=True)\n",
    "\n",
    "df_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8eb7547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Found o3-mini in your account. Using this model.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'o3-mini'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if o3-mini is available in YOUR account and set MODEL_ID accordingly\n",
    "\n",
    "want = \"o3-mini\"\n",
    "has_o3_mini = (df_models[\"model_id\"].str.contains(r\"\\bo3[-_]mini\\b\", case=False, na=False)).any()\n",
    "\n",
    "if has_o3_mini:\n",
    "    o3_row = df_models[df_models[\"model_id\"].str.contains(r\"\\bo3[-_]mini\\b\", case=False, na=False)].sort_values(\"model_id\").head(1)\n",
    "    MODEL_ID = o3_row.iloc[0][\"model_id\"]\n",
    "    print(f\"✅ Found {MODEL_ID} in your account. Using this model.\")\n",
    "else:\n",
    "    # sensible fallback if you don't have access\n",
    "    MODEL_ID = \"gpt-4.1-mini\"\n",
    "    print(\"⚠️ o3-mini not found on this account. Falling back to:\", MODEL_ID)\n",
    "\n",
    "MODEL_ID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9a1817b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model selected: o3-mini\n"
     ]
    }
   ],
   "source": [
    "MODEL_ID = \"o3-mini\"\n",
    "print(\"Model selected:\", MODEL_ID)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d1b3f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "o3-mini check OK ✅\n",
      "Sample output: OK\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import os\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "assert OPENAI_API_KEY, \"❌ Missing OPENAI_API_KEY\"\n",
    "\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "try:\n",
    "    resp = client.responses.create(\n",
    "        model=MODEL_ID,\n",
    "        input=\"Quick hello — please reply with 'OK' if you can hear me.\"\n",
    "    )\n",
    "    print(\"o3-mini check OK ✅\")\n",
    "    print(\"Sample output:\", resp.output_text[:120].replace(\"\\n\",\" \"))\n",
    "except Exception as e:\n",
    "    print(\"❌ Model check failed:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "da8e93c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_user_prompt(title: str, body: str) -> str:\n",
    "    return f\"\"\"\n",
    "You are a trauma-informed, non-judgmental peer-support assistant who responds to posts where the author is unsure if an experience counts as sexual abuse. \n",
    "Your tone must always be: gentle, validating, warm, and never blaming.\n",
    "\n",
    "You must avoid:\n",
    "- legal advice\n",
    "- medical advice\n",
    "\n",
    "Your response MUST:\n",
    "1. If the person got assaulted and they were confused about it, Explicitly mention that they got assaulted\n",
    "2. Validate the person's emotions and confusion\n",
    "3. Normalize uncertainty and mixed feelings\n",
    "4. Offer gentle perspective about consent and boundaries\n",
    "5. Gently suggest support options (trusted friend, partner, counselor, hotline), WITHOUT pressure\n",
    "6. Be 50-120 words long\n",
    "7. Use a warm, gentle, shame-free tone. No judgment, no criticism.\n",
    "8. Encourage self-compassion (one sentence reminding them they deserve care and clarity).\n",
    "9. Do not imply urgency unless the post states immediate danger.\n",
    "10. Use clear, simple, human language. No clinical jargon.\n",
    "\n",
    "Now respond to the following post:\n",
    "\n",
    "TITLE: {title}\n",
    "\n",
    "BODY:\n",
    "{body}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d167170a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_reply(title: str, body: str) -> str:\n",
    "    # Build the full prompt (since Responses API does not accept system=)\n",
    "    full_prompt = build_user_prompt(title, body)\n",
    "\n",
    "    # Make the model call\n",
    "    resp = client.responses.create(\n",
    "        model=MODEL_ID,\n",
    "        input=full_prompt,\n",
    "    )\n",
    "\n",
    "    # Extract model output text\n",
    "    return resp.output_text.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3f9c08f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It sounds like what you experienced does fit the description of assault, especially since you didn’t feel comfortable even if you didn’t verbally say no. Your confusion and guilt are totally understandable—these mixed feelings often happen when boundaries aren’t clearly honored. Consent should always feel safe and free, and your feelings matter. Please know that you deserve care and clarity. It might help to talk with someone you trust, a supportive friend, or a counselor who understands. Remember, you deserve compassion and care in processing these feelings. You are worthy of feeling safe and heard.\n"
     ]
    }
   ],
   "source": [
    "TEST_TITLE = \"I don’t know if what happened was assault\"\n",
    "TEST_BODY = (\n",
    "    \"I was with someone I trust and things escalated. I didn’t say no, but I also didn’t really want it. \"\n",
    "    \"Now I feel confused and guilty calling it assault. Part of me thinks I’m overreacting, but I can’t stop thinking about it.\"\n",
    ")\n",
    "\n",
    "reply = generate_reply(TEST_TITLE, TEST_BODY)\n",
    "print(reply)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7409da43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It sounds like what you experienced was a form of sexual assault—even though you initially said yes, being in a distressed state means your consent wasn’t fully informed or freely given, and that boundary wasn’t respected. It’s completely normal to feel confused and to question how you label your experience. Your feelings are valid, and it's okay to honor your journey by calling yourself a survivor if that resonates with you. Please consider talking with someone you trust or a supportive counselor whenever you feel ready. Remember, you deserve care, clarity, and compassion during this time.\n"
     ]
    }
   ],
   "source": [
    "TEST_TITLE = \"Can I consider myself a survivor?\"\n",
    "TEST_BODY = (\n",
    "    \"I was wondering if I can consider myself part of the survivor community even if my experience wasn’t necessarily forced/violent? My traumatic experience was medical related and I gave consent but I was in a very distressed state when I said yes and they did not stop immediately when I told them to for medical reasons, as a result I do have sexual related trauma from this experience. I would like to call myself a survivor but I’m worried that using the label even to myself would be insensitive or offensive to other people and women who have experienced more violent/nonconsensual situations. \"\n",
    ")\n",
    "\n",
    "reply = generate_reply(TEST_TITLE, TEST_BODY)\n",
    "print(reply)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
