{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fbc0304",
   "metadata": {},
   "source": [
    "# Support Multi-Label Pipeline (3-Step)\n",
    "This notebook:\n",
    "1) Loads `train.csv` (14 rows) to build few-shot examples  \n",
    "2) Loads `valid.csv` (86 rows) to predict labels  \n",
    "3) Runs 3 gates: Domain Gate → OP Last Comment Gate → Final Multi-label  \n",
    "4) Saves `valid_with_predictions.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd63ab61",
   "metadata": {},
   "source": [
    "## 1. Project Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee760aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: openai in /home/ec2-user/.local/lib/python3.11/site-packages (2.14.0)\n",
      "Requirement already satisfied: python-dotenv in /home/ec2-user/.local/lib/python3.11/site-packages (1.2.1)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/.local/lib/python3.11/site-packages (2.3.3)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/.local/lib/python3.11/site-packages (4.67.1)\n",
      "Requirement already satisfied: pydantic in /home/ec2-user/.local/lib/python3.11/site-packages (2.12.5)\n",
      "Requirement already satisfied: scikit-learn in /home/ec2-user/.local/lib/python3.11/site-packages (1.8.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/ec2-user/.local/lib/python3.11/site-packages (from openai) (4.12.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/ec2-user/.local/lib/python3.11/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/ec2-user/.local/lib/python3.11/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /home/ec2-user/.local/lib/python3.11/site-packages (from openai) (0.12.0)\n",
      "Requirement already satisfied: sniffio in /home/ec2-user/.local/lib/python3.11/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /home/ec2-user/.local/lib/python3.11/site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /home/ec2-user/.local/lib/python3.11/site-packages (from pandas) (2.3.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ec2-user/.local/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/.local/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ec2-user/.local/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ec2-user/.local/lib/python3.11/site-packages (from pydantic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /home/ec2-user/.local/lib/python3.11/site-packages (from pydantic) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /home/ec2-user/.local/lib/python3.11/site-packages (from pydantic) (0.4.2)\n",
      "Requirement already satisfied: scipy>=1.10.0 in /home/ec2-user/.local/lib/python3.11/site-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.3.0 in /home/ec2-user/.local/lib/python3.11/site-packages (from scikit-learn) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in /home/ec2-user/.local/lib/python3.11/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: idna>=2.8 in /home/ec2-user/.local/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
      "Requirement already satisfied: certifi in /home/ec2-user/.local/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /home/ec2-user/.local/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /home/ec2-user/.local/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/.local/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U openai python-dotenv pandas tqdm pydantic scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46d0dd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, time\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel\n",
    "from typing_extensions import Literal\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv()\n",
    "assert os.getenv(\"OPENAI_API_KEY\"), \"OPENAI_API_KEY not found in environment or .env\"\n",
    "\n",
    "client = OpenAI()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73ed77d",
   "metadata": {},
   "source": [
    "## 2. Loading files and definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a41eda0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>parent_fullname</th>\n",
       "      <th>depth</th>\n",
       "      <th>comment_author</th>\n",
       "      <th>comment_body</th>\n",
       "      <th>comment_score</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>...</th>\n",
       "      <th>body</th>\n",
       "      <th>prompt</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Information support</th>\n",
       "      <th>Emotional support</th>\n",
       "      <th>Esteem support</th>\n",
       "      <th>Network support</th>\n",
       "      <th>Tangible assistance</th>\n",
       "      <th>Seeking support</th>\n",
       "      <th>Group interactions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1lc7y2n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TooAfraidToAsk</td>\n",
       "      <td>mxysa7g</td>\n",
       "      <td>t3_1lc7y2n</td>\n",
       "      <td>0</td>\n",
       "      <td>Miaous95</td>\n",
       "      <td>Definitely SA and I’d do it back to him see if...</td>\n",
       "      <td>5</td>\n",
       "      <td>1750018747</td>\n",
       "      <td>...</td>\n",
       "      <td>So you have sex with a man with consent. You b...</td>\n",
       "      <td>Original Post:\\nAuthor: Beginning_Exit_6256\\nT...</td>\n",
       "      <td>Information support</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5rf97b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>relationship_advice</td>\n",
       "      <td>dd7kbxy</td>\n",
       "      <td>t3_5rf97b</td>\n",
       "      <td>0</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>You cheated on him. You are responsible for yo...</td>\n",
       "      <td>5</td>\n",
       "      <td>1485988490</td>\n",
       "      <td>...</td>\n",
       "      <td>My boyfriend (17/m) and I had been dating for ...</td>\n",
       "      <td>Original Post:\\nAuthor: ahhhhconfuse\\nTitle: D...</td>\n",
       "      <td>Information support</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id parent_id            subreddit comment_id parent_fullname  depth  \\\n",
       "0  1lc7y2n       NaN       TooAfraidToAsk    mxysa7g      t3_1lc7y2n      0   \n",
       "1   5rf97b       NaN  relationship_advice    dd7kbxy       t3_5rf97b      0   \n",
       "\n",
       "  comment_author                                       comment_body  \\\n",
       "0       Miaous95  Definitely SA and I’d do it back to him see if...   \n",
       "1      [deleted]  You cheated on him. You are responsible for yo...   \n",
       "\n",
       "   comment_score  created_utc  ...  \\\n",
       "0              5   1750018747  ...   \n",
       "1              5   1485988490  ...   \n",
       "\n",
       "                                                body  \\\n",
       "0  So you have sex with a man with consent. You b...   \n",
       "1  My boyfriend (17/m) and I had been dating for ...   \n",
       "\n",
       "                                              prompt                 Tags  \\\n",
       "0  Original Post:\\nAuthor: Beginning_Exit_6256\\nT...  Information support   \n",
       "1  Original Post:\\nAuthor: ahhhhconfuse\\nTitle: D...  Information support   \n",
       "\n",
       "  Information support Emotional support Esteem support Network support  \\\n",
       "0                 Yes                No             No              No   \n",
       "1                 Yes                No             No              No   \n",
       "\n",
       "  Tangible assistance Seeking support Group interactions  \n",
       "0                  No              No                 No  \n",
       "1                  No              No                 No  \n",
       "\n",
       "[2 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_PATH = \"../../data/train.csv\"\n",
    "VALID_PATH = \"../../data/valid.csv\"\n",
    "\n",
    "train_df = pd.read_csv(TRAIN_PATH)\n",
    "valid_df = pd.read_csv(VALID_PATH)\n",
    "\n",
    "assert \"prompt\" in train_df.columns, \"train.csv must contain a 'prompt' column\"\n",
    "assert \"prompt\" in valid_df.columns, \"valid.csv must contain a 'prompt' column\"\n",
    "\n",
    "train_df[\"prompt\"] = train_df[\"prompt\"].fillna(\"\").astype(str)\n",
    "valid_df[\"prompt\"] = valid_df[\"prompt\"].fillna(\"\").astype(str)\n",
    "\n",
    "train_df.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff3fd74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = [\n",
    "    \"Information support\",\n",
    "    \"Emotional support\",\n",
    "    \"Esteem support\",\n",
    "    \"Network support\",\n",
    "    \"Tangible assistance\",\n",
    "    \"Seeking support\",\n",
    "    \"Group interactions\",\n",
    "    \"Not applicable\",\n",
    "]\n",
    "\n",
    "SUPPORT_ONLY_LABELS = [\n",
    "    \"Information support\",\n",
    "    \"Emotional support\",\n",
    "    \"Esteem support\",\n",
    "    \"Network support\",\n",
    "    \"Tangible assistance\",\n",
    "    \"Seeking support\",\n",
    "    \"Group interactions\",\n",
    "]\n",
    "\n",
    "SUPPORT_DEFINITIONS = \"\"\"\n",
    "Information support: Giving advice, facts, resources, or explanations that clarify what’s happening or what to do (including opinionated judgments like “that is assault” when used to inform/guide).\n",
    "Emotional support: Messages that express care and empathy—comforting, showing affection/sympathy, encouraging hope, offering prayers, or easing guilt/blame (“I’m so sorry,” “sending hugs,” “stay strong,” “I’ll pray for you,” “it’s not your fault”).\n",
    "Esteem support: Messages that build the user up by complimenting them or validating their feelings/beliefs/actions as reasonable/normal.\n",
    "Network support: Encouraging the person to reach out to other people or connect with external help systems (therapy, friends, family, communities, etc.). Note : Suggesting to go to police is Information support and not Network support.\n",
    "Tangible assistance: When the commenter personally offers to help directly (I am here, You can talk to me).\n",
    "Seeking support: Messages where the author explicitly asks for help for themselves—either a direct question/request for info/suggestions or an explicit reassurance request.\n",
    "Group interactions: Any reply that primarily participates socially in the thread—expressing gratitude/thanks, congratulations, or sharing one’s own experience/story (including “me too” anecdotes). This label can co-occur with other support labels if the comment also gives advice, empathy, or info.\n",
    "\"\"\".strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ebab603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information support: YES count = 2\n",
      "Emotional support: YES count = 2\n",
      "Esteem support: YES count = 2\n",
      "Network support: YES count = 2\n",
      "Tangible assistance: YES count = 2\n",
      "Seeking support: YES count = 2\n",
      "Group interactions: YES count = 2\n"
     ]
    }
   ],
   "source": [
    "for lab in SUPPORT_ONLY_LABELS:\n",
    "    if lab not in train_df.columns:\n",
    "        print(f\"❌ Missing column: {lab}\")\n",
    "    else:\n",
    "        yes_count = (train_df[lab].astype(str).str.strip().str.lower() == \"yes\").sum()\n",
    "        print(f\"{lab}: YES count = {yes_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c934e56f",
   "metadata": {},
   "source": [
    "## 3. Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a20a634",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOMAIN_GATE_PROMPT = \"\"\"\n",
    "You are a psychologist and an expert in Reddit threads about possible sexual harassment/sexual assault.\n",
    "\n",
    "Task: DOMAIN GATE.\n",
    "\n",
    "Decide if the author is UNCERTAIN about whether the experience counts as sexual assault/harassment.\n",
    "\n",
    "Return true ONLY if the author explicitly questions whether the experience counts as SA/harassment.\n",
    "\n",
    "Return false otherwise.\n",
    "\n",
    "Return ONLY valid JSON:\n",
    "{{\n",
    "  \"is_ambivalent_sa_domain\": true/false\n",
    "}}\n",
    "\n",
    "Prompt:\n",
    "{prompt_text}\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "OP_LAST_COMMENT_PROMPT = \"\"\"\n",
    "Input format:\n",
    "- There is an \"Original Post:\" section with Author, Title, Body.\n",
    "- There is a \"Conversation History:\" section with a single/multiple comments.\n",
    "\"Conversation History:\" includes blocks like:\n",
    "  Comment (depth X):\n",
    "  Author: ... \n",
    "  Content: ...\n",
    "\n",
    "Steps:\n",
    "1) Extract OP from \"Original Post: Author:\"\n",
    "2) Choose the comment with the highest depth in the conversation history.\n",
    "3) Extract that last comment's Author, Depth, and Content.\n",
    "4) Compare last comment author with OP.\n",
    "\n",
    "Return ONLY valid JSON:\n",
    "{{\n",
    "  \"op_author\": \"<string>\",\n",
    "  \"last_comment_depth\": <int>,\n",
    "  \"last_comment_author\": \"<string>\",\n",
    "  \"last_comment_content\": \"<string>\",\n",
    "  \"is_last_comment_by_op\": true/false\n",
    "}}\n",
    "\n",
    "Prompt:\n",
    "{prompt_text}\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "FINAL_MULTILABEL_PROMPT = \"\"\"\n",
    "You are a psychologist expert in identifying support in Reddit comments. \n",
    "\n",
    "You will label ONLY this comment (the last comment in the thread):\n",
    "Last Comment Author: {last_comment_author}\n",
    "Last Comment Content: {last_comment_content}\n",
    "\n",
    "Gates (already computed):\n",
    "- is_ambivalent_sa_domain: {is_ambivalent_sa_domain}\n",
    "- is_last_comment_by_op: {is_last_comment_by_op}\n",
    "\n",
    "Rules:\n",
    "1) If is_ambivalent_sa_domain is false:\n",
    "   - Output: Not applicable = YES, and all other labels = NO. Stop.\n",
    "\n",
    "2) If is_last_comment_by_op is true:\n",
    "   - Only evaluate: Seeking support.\n",
    "   - Force: Information support/Emotional support/Esteem support/Network support/Tangible assistance = NO.\n",
    "   - Default rule:\n",
    "     * If Seeking support = NO, then Group interactions = YES.\n",
    "     * Else evaluate Group interactions.\n",
    "\n",
    "                \n",
    "3) Otherwise:\n",
    "   - Only evaluate: Information support, Emotional support, Esteem support, Network support, Tangible assistance, Group interactions.\n",
    "   - Force: Seeking support = NO.\n",
    "   - Not applicable = YES only if all evaluated labels are NO.\n",
    "\n",
    "Definitions:\n",
    "{support_definitions}\n",
    "\n",
    "Few-shot examples:\n",
    "{few_shot_examples}\n",
    "\n",
    "Return ONLY valid JSON with all labels:\n",
    "{{\n",
    "  \"Information support\": \"YES/NO\",\n",
    "  \"Emotional support\": \"YES/NO\",\n",
    "  \"Esteem support\": \"YES/NO\",\n",
    "  \"Network support\": \"YES/NO\",\n",
    "  \"Tangible assistance\": \"YES/NO\",\n",
    "  \"Seeking support\": \"YES/NO\",\n",
    "  \"Group interactions\": \"YES/NO\",\n",
    "  \"Not applicable\": \"YES/NO\"\n",
    "}}\n",
    "\n",
    "Prompt:\n",
    "{prompt_text}\n",
    "\"\"\".strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a77ff79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_title_body(full_prompt: str):\n",
    "    if not full_prompt or not isinstance(full_prompt, str):\n",
    "        return \"\", \"\"\n",
    "    title_m = re.search(r\"Title:\\s*(.*)\", full_prompt)\n",
    "    body_m  = re.search(r\"Body:\\s*(.*?)(?:\\n---\\n|Conversation History:|\\Z)\", full_prompt, flags=re.DOTALL)\n",
    "    title = title_m.group(1).strip() if title_m else \"\"\n",
    "    body  = body_m.group(1).strip() if body_m else \"\"\n",
    "    return title, body\n",
    "\n",
    "def build_gate_title_only(full_prompt: str) -> str:\n",
    "    title, _ = extract_title_body(full_prompt)\n",
    "    return f\"\"\"Original Post:\n",
    "Title: {title}\n",
    "\"\"\".strip()\n",
    "\n",
    "def build_gate_full_op(full_prompt: str) -> str:\n",
    "    title, body = extract_title_body(full_prompt)\n",
    "    return f\"\"\"Original Post:\n",
    "Title: {title}\n",
    "Body: {body}\n",
    "\"\"\".strip()\n",
    "\n",
    "def domain_gate_title_then_fullbody(model: str, full_prompt: str):\n",
    "    \"\"\"\n",
    "    Gate 1: Title-only\n",
    "    If false -> Gate 2: Title + full Body (no comments)\n",
    "    \"\"\"\n",
    "    gate1_text = build_gate_title_only(full_prompt)\n",
    "    dg1 = call_structured(model, DOMAIN_GATE_PROMPT.format(prompt_text=gate1_text), DomainGateOut)\n",
    "    if dg1.is_ambivalent_sa_domain:\n",
    "        return dg1, \"title_only\"\n",
    "\n",
    "    gate2_text = build_gate_full_op(full_prompt)\n",
    "    dg2 = call_structured(model, DOMAIN_GATE_PROMPT.format(prompt_text=gate2_text), DomainGateOut)\n",
    "    return dg2, \"full_body_fallback\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a597086f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field, ConfigDict\n",
    "from typing_extensions import Literal\n",
    "\n",
    "class DomainGateOut(BaseModel):\n",
    "    is_ambivalent_sa_domain: bool\n",
    "\n",
    "class LastCommentOut(BaseModel):\n",
    "    op_author: str\n",
    "    last_comment_depth: int\n",
    "    last_comment_author: str\n",
    "    last_comment_content: str\n",
    "    is_last_comment_by_op: bool\n",
    "\n",
    "YesNo = Literal[\"YES\", \"NO\"]\n",
    "\n",
    "class MultiLabelOut(BaseModel):\n",
    "    model_config = ConfigDict(populate_by_name=True)\n",
    "\n",
    "    Information_support: YesNo = Field(alias=\"Information support\")\n",
    "    Emotional_support: YesNo = Field(alias=\"Emotional support\")\n",
    "    Esteem_support: YesNo = Field(alias=\"Esteem support\")\n",
    "    Network_support: YesNo = Field(alias=\"Network support\")\n",
    "    Tangible_assistance: YesNo = Field(alias=\"Tangible assistance\")\n",
    "    Seeking_support: YesNo = Field(alias=\"Seeking support\")\n",
    "    Group_interactions: YesNo = Field(alias=\"Group interactions\")\n",
    "    Not_applicable: YesNo = Field(alias=\"Not applicable\")\n",
    "\n",
    "    def to_label_dict(self):\n",
    "        return {\n",
    "            \"Information support\": self.Information_support,\n",
    "            \"Emotional support\": self.Emotional_support,\n",
    "            \"Esteem support\": self.Esteem_support,\n",
    "            \"Network support\": self.Network_support,\n",
    "            \"Tangible assistance\": self.Tangible_assistance,\n",
    "            \"Seeking support\": self.Seeking_support,\n",
    "            \"Group interactions\": self.Group_interactions,\n",
    "            \"Not applicable\": self.Not_applicable,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0de256",
   "metadata": {},
   "source": [
    "## 4. OpenAI Call Helper (Structured Parse) + Build examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "797ca47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, time\n",
    "\n",
    "def _retry_after_seconds(err: Exception) -> float | None:\n",
    "    msg = str(err)\n",
    "    m = re.search(r\"try again in ([0-9.]+)ms\", msg, re.IGNORECASE)\n",
    "    if m:\n",
    "        return float(m.group(1)) / 1000.0\n",
    "    m = re.search(r\"try again in ([0-9.]+)s\", msg, re.IGNORECASE)\n",
    "    if m:\n",
    "        return float(m.group(1))\n",
    "    return None\n",
    "\n",
    "def call_structured(model: str, prompt: str, out_schema, max_retries: int = 12):\n",
    "    last_err = None\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            resp = client.responses.parse(\n",
    "                model=model,\n",
    "                input=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                text_format=out_schema,\n",
    "                max_output_tokens=350,  # IMPORTANT: cap output to reduce token reservation\n",
    "            )\n",
    "            return resp.output_parsed\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "            ra = _retry_after_seconds(e)\n",
    "\n",
    "            # If server tells us exactly when to retry, obey it.\n",
    "            if ra is not None:\n",
    "                sleep_s = ra + 0.2\n",
    "            else:\n",
    "                # Gentle fallback backoff (not explosive)\n",
    "                sleep_s = min(8.0, 0.5 * (1.5 ** (attempt + 1)))\n",
    "\n",
    "            print(f\"[retry {attempt+1}/{max_retries}] {type(e).__name__}: sleeping {sleep_s:.2f}s\")\n",
    "            time.sleep(sleep_s)\n",
    "\n",
    "    raise RuntimeError(f\"OpenAI call failed after retries. Last error: {last_err}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7b76cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 1:\n",
      "Prompt:\n",
      "Original Post:\n",
      "Author: Beginning_Exit_6256\n",
      "Title: Is this considered sexual assault?\n",
      "Body: So you have sex with a man with consent. You both want to have sex. You tell him that you don’t swallow semen and you’ve never done that. He tells you to do it but you don’t\n",
      "\n",
      "He then thinks it’s funny/as a joke to force some of his semen with his hand in your mouth? He forcibly does this with his hand\n",
      "\n",
      "Is this sexual assault?\n",
      "\n",
      "edit: he’d probably just get arrested for that. I don’t he’d go to prison for it though lol\n",
      "\n",
      "---\n",
      "Conversation History:\n",
      "Comment (depth 0):\n",
      "Author: Miaous95\n",
      "Content: Definitely SA and I’d do it back to him see if he finds it funny\n",
      "\n",
      "Gold labels (JSON):\n",
      "{\"Information support\": \"YES\", \"Emotional support\": \"NO\", \"Esteem support\": \"NO\", \"Network support\": \"NO\", \"Tangible assistance\": \"NO\", \"Seeking support\": \"NO\", \"Group interactions\": \"NO\", \"Not applicable\": \"NO\"}\n",
      "\n",
      "\n",
      "Example 2:\n",
      "Prompt:\n",
      "Original Post:\n",
      "Author: ahhhhconfuse\n",
      "Title: Did I (17/f) cheat on my boyfriend or was I sexually assaulted?\n",
      "Body: My boyfriend (17/m) and I had been dating for a year, and we really loved each other. There was nothing about him I disliked and I really enjoyed being in this rela\n"
     ]
    }
   ],
   "source": [
    "def build_few_shot_examples(train_df: pd.DataFrame) -> str:\n",
    "    missing = [lab for lab in SUPPORT_ONLY_LABELS if lab not in train_df.columns]\n",
    "    if missing:\n",
    "        print(\"❌ Missing label columns:\", missing)\n",
    "        return \"NO_FEW_SHOT_AVAILABLE\"\n",
    "\n",
    "    blocks = []\n",
    "    idx = 1\n",
    "\n",
    "    for lab in SUPPORT_ONLY_LABELS:\n",
    "        positives = train_df[train_df[lab].astype(str).str.strip().str.lower().eq(\"yes\")].head(2)\n",
    "        if len(positives) < 2:\n",
    "            print(f\"WARNING: label '{lab}' has only {len(positives)} YES rows\")\n",
    "\n",
    "        for _, row in positives.iterrows():\n",
    "            gold = {c: \"NO\" for c in LABELS}\n",
    "            for c in LABELS:\n",
    "                if c in train_df.columns:\n",
    "                    gold[c] = str(row.get(c, \"NO\")).strip().upper()\n",
    "\n",
    "            if \"Not applicable\" not in train_df.columns:\n",
    "                gold[\"Not applicable\"] = \"YES\" if all(gold[x] == \"NO\" for x in SUPPORT_ONLY_LABELS) else \"NO\"\n",
    "\n",
    "            blocks.append(\n",
    "                f\"Example {idx}:\\n\"\n",
    "                f\"Prompt:\\n{row['prompt']}\\n\\n\"\n",
    "                f\"Gold labels (JSON):\\n{json.dumps(gold, ensure_ascii=False)}\\n\"\n",
    "            )\n",
    "            idx += 1\n",
    "\n",
    "    return \"\\n\\n\".join(blocks).strip()\n",
    "\n",
    "few_shot_examples = build_few_shot_examples(train_df)\n",
    "print(few_shot_examples[:1200])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e88380",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9cc1c23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total models visible: 114\n",
      "\n",
      "babbage-002\n",
      "chatgpt-4o-latest\n",
      "chatgpt-image-latest\n",
      "codex-mini-latest\n",
      "dall-e-2\n",
      "dall-e-3\n",
      "davinci-002\n",
      "gpt-3.5-turbo\n",
      "gpt-3.5-turbo-0125\n",
      "gpt-3.5-turbo-1106\n",
      "gpt-3.5-turbo-16k\n",
      "gpt-3.5-turbo-instruct\n",
      "gpt-3.5-turbo-instruct-0914\n",
      "gpt-4\n",
      "gpt-4-0125-preview\n",
      "gpt-4-0613\n",
      "gpt-4-1106-preview\n",
      "gpt-4-turbo\n",
      "gpt-4-turbo-2024-04-09\n",
      "gpt-4-turbo-preview\n",
      "gpt-4.1\n",
      "gpt-4.1-2025-04-14\n",
      "gpt-4.1-mini\n",
      "gpt-4.1-mini-2025-04-14\n",
      "gpt-4.1-nano\n",
      "gpt-4.1-nano-2025-04-14\n",
      "gpt-4o\n",
      "gpt-4o-2024-05-13\n",
      "gpt-4o-2024-08-06\n",
      "gpt-4o-2024-11-20\n",
      "gpt-4o-audio-preview\n",
      "gpt-4o-audio-preview-2024-12-17\n",
      "gpt-4o-audio-preview-2025-06-03\n",
      "gpt-4o-mini\n",
      "gpt-4o-mini-2024-07-18\n",
      "gpt-4o-mini-audio-preview\n",
      "gpt-4o-mini-audio-preview-2024-12-17\n",
      "gpt-4o-mini-realtime-preview\n",
      "gpt-4o-mini-realtime-preview-2024-12-17\n",
      "gpt-4o-mini-search-preview\n",
      "gpt-4o-mini-search-preview-2025-03-11\n",
      "gpt-4o-mini-transcribe\n",
      "gpt-4o-mini-transcribe-2025-03-20\n",
      "gpt-4o-mini-transcribe-2025-12-15\n",
      "gpt-4o-mini-tts\n",
      "gpt-4o-mini-tts-2025-03-20\n",
      "gpt-4o-mini-tts-2025-12-15\n",
      "gpt-4o-realtime-preview\n",
      "gpt-4o-realtime-preview-2024-12-17\n",
      "gpt-4o-realtime-preview-2025-06-03\n",
      "gpt-4o-search-preview\n",
      "gpt-4o-search-preview-2025-03-11\n",
      "gpt-4o-transcribe\n",
      "gpt-4o-transcribe-diarize\n",
      "gpt-5\n",
      "gpt-5-2025-08-07\n",
      "gpt-5-chat-latest\n",
      "gpt-5-codex\n",
      "gpt-5-mini\n",
      "gpt-5-mini-2025-08-07\n",
      "gpt-5-nano\n",
      "gpt-5-nano-2025-08-07\n",
      "gpt-5-pro\n",
      "gpt-5-pro-2025-10-06\n",
      "gpt-5-search-api\n",
      "gpt-5-search-api-2025-10-14\n",
      "gpt-5.1\n",
      "gpt-5.1-2025-11-13\n",
      "gpt-5.1-chat-latest\n",
      "gpt-5.1-codex\n",
      "gpt-5.1-codex-max\n",
      "gpt-5.1-codex-mini\n",
      "gpt-5.2\n",
      "gpt-5.2-2025-12-11\n",
      "gpt-5.2-chat-latest\n",
      "gpt-5.2-pro\n",
      "gpt-5.2-pro-2025-12-11\n",
      "gpt-audio\n",
      "gpt-audio-2025-08-28\n",
      "gpt-audio-mini\n",
      "gpt-audio-mini-2025-10-06\n",
      "gpt-audio-mini-2025-12-15\n",
      "gpt-image-1\n",
      "gpt-image-1-mini\n",
      "gpt-image-1.5\n",
      "gpt-realtime\n",
      "gpt-realtime-2025-08-28\n",
      "gpt-realtime-mini\n",
      "gpt-realtime-mini-2025-10-06\n",
      "gpt-realtime-mini-2025-12-15\n",
      "o1\n",
      "o1-2024-12-17\n",
      "o1-pro\n",
      "o1-pro-2025-03-19\n",
      "o3\n",
      "o3-2025-04-16\n",
      "o3-mini\n",
      "o3-mini-2025-01-31\n",
      "o4-mini\n",
      "o4-mini-2025-04-16\n",
      "o4-mini-deep-research\n",
      "o4-mini-deep-research-2025-06-26\n",
      "omni-moderation-2024-09-26\n",
      "omni-moderation-latest\n",
      "sora-2\n",
      "sora-2-pro\n",
      "text-embedding-3-large\n",
      "text-embedding-3-small\n",
      "text-embedding-ada-002\n",
      "tts-1\n",
      "tts-1-1106\n",
      "tts-1-hd\n",
      "tts-1-hd-1106\n",
      "whisper-1\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "models = client.models.list()\n",
    "\n",
    "# Print nicely\n",
    "ids = sorted([m.id for m in models.data])\n",
    "print(f\"Total models visible: {len(ids)}\\n\")\n",
    "for mid in ids:\n",
    "    print(mid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22553553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row: 3\n",
      "FULL prompt preview:\n",
      " Original Post:\n",
      "Author: katiedababie\n",
      "Title: I (21F) found a spy camera in my room after my step dad (36M) put a surveillance camera in my window\n",
      "Body: My stepdad (36M) installed a surveillance camera positioned outside of my window to scan our backyard while him and my mother and two younger brothers go camping. I couldn’t go on the trip since i had work, so i was staying home to house sit and feed our animals. My stepdad recently put up new cameras outside so I didn’t see anything wrong with him \n",
      "\n",
      "DOMAIN GATE: is_ambivalent_sa_domain=False | gate_used: full_body_fallback\n",
      "\n",
      "FINAL LABELS (forced):\n",
      "{\n",
      "  \"Information support\": \"NO\",\n",
      "  \"Emotional support\": \"NO\",\n",
      "  \"Esteem support\": \"NO\",\n",
      "  \"Network support\": \"NO\",\n",
      "  \"Tangible assistance\": \"NO\",\n",
      "  \"Seeking support\": \"NO\",\n",
      "  \"Group interactions\": \"NO\",\n",
      "  \"Not applicable\": \"YES\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "MODEL = \"gpt-4.1-mini\"\n",
    "i = 3\n",
    "full_prompt_text = valid_df.iloc[i][\"prompt\"]\n",
    "\n",
    "print(\"Row:\", i)\n",
    "print(\"FULL prompt preview:\\n\", full_prompt_text[:500], \"\\n\")\n",
    "\n",
    "# Step 1: Domain gate (title-only → fallback full body)\n",
    "dg_out, gate_used = domain_gate_title_then_fullbody(MODEL, full_prompt_text)\n",
    "print(\"DOMAIN GATE:\", dg_out, \"| gate_used:\", gate_used)\n",
    "\n",
    "if not dg_out.is_ambivalent_sa_domain:\n",
    "    pred = {lab: \"NO\" for lab in SUPPORT_ONLY_LABELS}\n",
    "    pred[\"Not applicable\"] = \"YES\"\n",
    "    print(\"\\nFINAL LABELS (forced):\")\n",
    "    print(json.dumps(pred, indent=2))\n",
    "else:\n",
    "    # Step 2\n",
    "    op_out = call_structured(MODEL, OP_LAST_COMMENT_PROMPT.format(prompt_text=full_prompt_text), LastCommentOut)\n",
    "    print(\"OP LAST COMMENT:\", op_out)\n",
    "\n",
    "    # Step 3\n",
    "    final_prompt = FINAL_MULTILABEL_PROMPT.format(\n",
    "        is_ambivalent_sa_domain=str(dg_out.is_ambivalent_sa_domain).lower(),\n",
    "        is_last_comment_by_op=str(op_out.is_last_comment_by_op).lower(),\n",
    "        last_comment_author=op_out.last_comment_author,\n",
    "        last_comment_content=op_out.last_comment_content,\n",
    "        support_definitions=SUPPORT_DEFINITIONS,\n",
    "        few_shot_examples=few_shot_examples,\n",
    "        prompt_text=full_prompt_text,\n",
    "    )\n",
    "    ml_out = call_structured(MODEL, final_prompt, MultiLabelOut)\n",
    "    pred = ml_out.to_label_dict()\n",
    "\n",
    "    print(\"\\nFINAL LABELS:\")\n",
    "    print(json.dumps(pred, indent=2))\n",
    "\n",
    "    yes_labels = [lab for lab in LABELS if pred.get(lab) == \"YES\"]\n",
    "    print(\"\\nYES labels:\", \", \".join(yes_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b153bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Full validation (workers=1):   0%|          | 0/86 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Full validation (workers=1):  66%|██████▋   | 57/86 [04:40<02:18,  4.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[retry 1/12] ValidationError: sleeping 0.75s\n",
      "[retry 2/12] ValidationError: sleeping 1.12s\n",
      "[retry 3/12] ValidationError: sleeping 1.69s\n",
      "[retry 4/12] ValidationError: sleeping 2.53s\n",
      "[retry 5/12] ValidationError: sleeping 3.80s\n",
      "[retry 6/12] ValidationError: sleeping 5.70s\n",
      "[retry 7/12] ValidationError: sleeping 8.00s\n",
      "[retry 8/12] ValidationError: sleeping 8.00s\n",
      "[retry 9/12] ValidationError: sleeping 8.00s\n",
      "[retry 10/12] ValidationError: sleeping 8.00s\n",
      "[retry 11/12] ValidationError: sleeping 8.00s\n",
      "[retry 12/12] ValidationError: sleeping 8.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Full validation (workers=1):  72%|███████▏  | 62/86 [07:10<05:36, 14.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[retry 1/12] ValidationError: sleeping 0.75s\n",
      "[retry 2/12] ValidationError: sleeping 1.12s\n",
      "[retry 3/12] ValidationError: sleeping 1.69s\n",
      "[retry 4/12] ValidationError: sleeping 2.53s\n",
      "[retry 5/12] ValidationError: sleeping 3.80s\n",
      "[retry 6/12] ValidationError: sleeping 5.70s\n",
      "[retry 7/12] ValidationError: sleeping 8.00s\n",
      "[retry 8/12] ValidationError: sleeping 8.00s\n",
      "[retry 9/12] ValidationError: sleeping 8.00s\n",
      "[retry 10/12] ValidationError: sleeping 8.00s\n",
      "[retry 11/12] ValidationError: sleeping 8.00s\n",
      "[retry 12/12] ValidationError: sleeping 8.00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Full validation (workers=1): 100%|██████████| 86/86 [10:59<00:00,  7.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: valid_with_predictions_4mini.csv\n",
      "Left existing 'Tags' untouched. Errors are in 'llm_error'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures as cf\n",
    "from tqdm import tqdm\n",
    "\n",
    "MODEL = \"gpt-4.1-mini\"\n",
    "MAX_WORKERS = 1   # start low; increase only if you stop seeing 429s\n",
    "\n",
    "ERROR_COL = \"llm_error\"\n",
    "YES_LABEL_COL = \"predicted_labels_yes\"\n",
    "GATE_USED_COL = \"gate_used\"\n",
    "\n",
    "# Ensure OUR output columns exist (do NOT touch Tags)\n",
    "base_cols = [\n",
    "    \"is_ambivalent_sa_domain\",\n",
    "    \"op_author\",\n",
    "    \"last_comment_depth\",\n",
    "    \"last_comment_author\",\n",
    "    \"is_last_comment_by_op\",\n",
    "    ERROR_COL,\n",
    "    YES_LABEL_COL,\n",
    "    GATE_USED_COL,\n",
    "]\n",
    "for col in base_cols:\n",
    "    if col not in valid_df.columns:\n",
    "        valid_df[col] = None\n",
    "\n",
    "for lab in LABELS:\n",
    "    if lab not in valid_df.columns:\n",
    "        valid_df[lab] = None\n",
    "\n",
    "def run_one(full_prompt_text: str):\n",
    "    # Step 1: title-only → fallback full body\n",
    "    dg_out, gate_used = domain_gate_title_then_fullbody(MODEL, full_prompt_text)\n",
    "\n",
    "    if not dg_out.is_ambivalent_sa_domain:\n",
    "        pred = {lab: \"NO\" for lab in SUPPORT_ONLY_LABELS}\n",
    "        pred[\"Not applicable\"] = \"YES\"\n",
    "        yes_labels = [lab for lab, v in pred.items() if v == \"YES\"]\n",
    "        return {\n",
    "            \"gate_used\": gate_used,\n",
    "            \"is_ambivalent_sa_domain\": False,\n",
    "            \"op_author\": None,\n",
    "            \"last_comment_depth\": None,\n",
    "            \"last_comment_author\": None,\n",
    "            \"is_last_comment_by_op\": None,\n",
    "            \"pred\": pred,\n",
    "            \"predicted_labels_yes\": \", \".join(yes_labels),\n",
    "            \"error\": None,\n",
    "        }\n",
    "\n",
    "    # Step 2\n",
    "    op_out = call_structured(MODEL, OP_LAST_COMMENT_PROMPT.format(prompt_text=full_prompt_text), LastCommentOut)\n",
    "\n",
    "    # Step 3\n",
    "    final_prompt = FINAL_MULTILABEL_PROMPT.format(\n",
    "        is_ambivalent_sa_domain=str(dg_out.is_ambivalent_sa_domain).lower(),\n",
    "        is_last_comment_by_op=str(op_out.is_last_comment_by_op).lower(),\n",
    "        last_comment_author=op_out.last_comment_author,\n",
    "        last_comment_content=op_out.last_comment_content,\n",
    "        support_definitions=SUPPORT_DEFINITIONS,\n",
    "        few_shot_examples=few_shot_examples,\n",
    "        prompt_text=full_prompt_text,\n",
    "    )\n",
    "    ml_out = call_structured(MODEL, final_prompt, MultiLabelOut)\n",
    "    pred = ml_out.to_label_dict()\n",
    "    yes_labels = [lab for lab, v in pred.items() if v == \"YES\"]\n",
    "\n",
    "    return {\n",
    "        \"gate_used\": gate_used,\n",
    "        \"is_ambivalent_sa_domain\": True,\n",
    "        \"op_author\": op_out.op_author,\n",
    "        \"last_comment_depth\": op_out.last_comment_depth,\n",
    "        \"last_comment_author\": op_out.last_comment_author,\n",
    "        \"is_last_comment_by_op\": op_out.is_last_comment_by_op,\n",
    "        \"pred\": pred,\n",
    "        \"predicted_labels_yes\": \", \".join(yes_labels),\n",
    "        \"error\": None,\n",
    "    }\n",
    "\n",
    "# Parallel run\n",
    "futures = {}\n",
    "with cf.ThreadPoolExecutor(max_workers=MAX_WORKERS) as ex:\n",
    "    for i, row in valid_df.iterrows():\n",
    "        # Optional resume: skip rows already done successfully\n",
    "        if pd.notna(row.get(YES_LABEL_COL)) and str(row.get(ERROR_COL, \"\")).strip() in {\"\", \"nan\", \"None\"}:\n",
    "            continue\n",
    "        futures[ex.submit(run_one, row[\"prompt\"])] = i\n",
    "\n",
    "    for fut in tqdm(cf.as_completed(futures), total=len(futures), desc=f\"Full validation (workers={MAX_WORKERS})\"):\n",
    "        i = futures[fut]\n",
    "        try:\n",
    "            out = fut.result()\n",
    "\n",
    "            valid_df.at[i, GATE_USED_COL] = out[\"gate_used\"]\n",
    "            valid_df.at[i, \"is_ambivalent_sa_domain\"] = out[\"is_ambivalent_sa_domain\"]\n",
    "            valid_df.at[i, \"op_author\"] = out[\"op_author\"]\n",
    "            valid_df.at[i, \"last_comment_depth\"] = out[\"last_comment_depth\"]\n",
    "            valid_df.at[i, \"last_comment_author\"] = out[\"last_comment_author\"]\n",
    "            valid_df.at[i, \"is_last_comment_by_op\"] = out[\"is_last_comment_by_op\"]\n",
    "\n",
    "            for lab, val in out[\"pred\"].items():\n",
    "                valid_df.at[i, lab] = val\n",
    "\n",
    "            valid_df.at[i, YES_LABEL_COL] = out[\"predicted_labels_yes\"]\n",
    "            valid_df.at[i, ERROR_COL] = out[\"error\"]\n",
    "\n",
    "        except Exception as e:\n",
    "            valid_df.at[i, ERROR_COL] = str(e)\n",
    "\n",
    "# Save once\n",
    "OUT_PATH = \"valid_with_predictions_4mini.csv\"\n",
    "valid_df.to_csv(OUT_PATH, index=False)\n",
    "print(\"Saved:\", OUT_PATH)\n",
    "print(f\"Left existing 'Tags' untouched. Errors are in '{ERROR_COL}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "099c932e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reset done. Now rerun full validation with o4-mini.\n"
     ]
    }
   ],
   "source": [
    "cols_to_reset = [\n",
    "    \"is_ambivalent_sa_domain\",\"op_author\",\"last_comment_depth\",\"last_comment_author\",\"is_last_comment_by_op\",\n",
    "    \"gate_used\",\"llm_error\",\"predicted_labels_yes\",\n",
    "    \"Information support\",\"Emotional support\",\"Esteem support\",\"Network support\",\n",
    "    \"Tangible assistance\",\"Seeking support\",\"Group interactions\",\"Not applicable\",\n",
    "]\n",
    "for c in cols_to_reset:\n",
    "    if c in valid_df.columns:\n",
    "        valid_df[c] = None\n",
    "\n",
    "print(\"Reset done. Now rerun full validation with o4-mini.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "45600401",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Full validation (workers=2):   0%|          | 0/86 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Full validation (workers=2):  31%|███▏      | 27/86 [01:52<03:47,  3.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[retry 1/12] ValidationError: sleeping 0.75s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Full validation (workers=2):  52%|█████▏    | 45/86 [03:40<03:55,  5.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[retry 1/12] ValidationError: sleeping 0.75s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Full validation (workers=2):  62%|██████▏   | 53/86 [04:34<03:18,  6.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[retry 1/12] ValidationError: sleeping 0.75s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Full validation (workers=2):  92%|█████████▏| 79/86 [06:27<00:26,  3.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[retry 1/12] ValidationError: sleeping 0.75s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Full validation (workers=2):  93%|█████████▎| 80/86 [06:30<00:21,  3.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[retry 1/12] ValidationError: sleeping 0.75s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Full validation (workers=2): 100%|██████████| 86/86 [06:55<00:00,  4.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: valid_with_predictions_o4mini.csv\n",
      "Left existing 'Tags' untouched. Errors are in 'llm_error'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures as cf\n",
    "from tqdm import tqdm\n",
    "\n",
    "MODEL = \"o4-mini\"\n",
    "MAX_WORKERS = 2   # start low; increase only if you stop seeing 429s\n",
    "\n",
    "ERROR_COL = \"llm_error\"\n",
    "YES_LABEL_COL = \"predicted_labels_yes\"\n",
    "GATE_USED_COL = \"gate_used\"\n",
    "\n",
    "# Ensure OUR output columns exist (do NOT touch Tags)\n",
    "base_cols = [\n",
    "    \"is_ambivalent_sa_domain\",\n",
    "    \"op_author\",\n",
    "    \"last_comment_depth\",\n",
    "    \"last_comment_author\",\n",
    "    \"is_last_comment_by_op\",\n",
    "    ERROR_COL,\n",
    "    YES_LABEL_COL,\n",
    "    GATE_USED_COL,\n",
    "]\n",
    "for col in base_cols:\n",
    "    if col not in valid_df.columns:\n",
    "        valid_df[col] = None\n",
    "\n",
    "for lab in LABELS:\n",
    "    if lab not in valid_df.columns:\n",
    "        valid_df[lab] = None\n",
    "\n",
    "def run_one(full_prompt_text: str):\n",
    "    # Step 1: title-only → fallback full body\n",
    "    dg_out, gate_used = domain_gate_title_then_fullbody(MODEL, full_prompt_text)\n",
    "\n",
    "    if not dg_out.is_ambivalent_sa_domain:\n",
    "        pred = {lab: \"NO\" for lab in SUPPORT_ONLY_LABELS}\n",
    "        pred[\"Not applicable\"] = \"YES\"\n",
    "        yes_labels = [lab for lab, v in pred.items() if v == \"YES\"]\n",
    "        return {\n",
    "            \"gate_used\": gate_used,\n",
    "            \"is_ambivalent_sa_domain\": False,\n",
    "            \"op_author\": None,\n",
    "            \"last_comment_depth\": None,\n",
    "            \"last_comment_author\": None,\n",
    "            \"is_last_comment_by_op\": None,\n",
    "            \"pred\": pred,\n",
    "            \"predicted_labels_yes\": \", \".join(yes_labels),\n",
    "            \"error\": None,\n",
    "        }\n",
    "\n",
    "    # Step 2\n",
    "    op_out = call_structured(MODEL, OP_LAST_COMMENT_PROMPT.format(prompt_text=full_prompt_text), LastCommentOut)\n",
    "\n",
    "    # Step 3\n",
    "    final_prompt = FINAL_MULTILABEL_PROMPT.format(\n",
    "        is_ambivalent_sa_domain=str(dg_out.is_ambivalent_sa_domain).lower(),\n",
    "        is_last_comment_by_op=str(op_out.is_last_comment_by_op).lower(),\n",
    "        support_definitions=SUPPORT_DEFINITIONS,\n",
    "        few_shot_examples=few_shot_examples,\n",
    "        prompt_text=full_prompt_text,\n",
    "    )\n",
    "    ml_out = call_structured(MODEL, final_prompt, MultiLabelOut)\n",
    "    pred = ml_out.to_label_dict()\n",
    "    yes_labels = [lab for lab, v in pred.items() if v == \"YES\"]\n",
    "\n",
    "    return {\n",
    "        \"gate_used\": gate_used,\n",
    "        \"is_ambivalent_sa_domain\": True,\n",
    "        \"op_author\": op_out.op_author,\n",
    "        \"last_comment_depth\": op_out.last_comment_depth,\n",
    "        \"last_comment_author\": op_out.last_comment_author,\n",
    "        \"is_last_comment_by_op\": op_out.is_last_comment_by_op,\n",
    "        \"pred\": pred,\n",
    "        \"predicted_labels_yes\": \", \".join(yes_labels),\n",
    "        \"error\": None,\n",
    "    }\n",
    "\n",
    "# Parallel run\n",
    "futures = {}\n",
    "with cf.ThreadPoolExecutor(max_workers=MAX_WORKERS) as ex:\n",
    "    for i, row in valid_df.iterrows():\n",
    "        # Optional resume: skip rows already done successfully\n",
    "        if pd.notna(row.get(YES_LABEL_COL)) and str(row.get(ERROR_COL, \"\")).strip() in {\"\", \"nan\", \"None\"}:\n",
    "            continue\n",
    "        futures[ex.submit(run_one, row[\"prompt\"])] = i\n",
    "\n",
    "    for fut in tqdm(cf.as_completed(futures), total=len(futures), desc=f\"Full validation (workers={MAX_WORKERS})\"):\n",
    "        i = futures[fut]\n",
    "        try:\n",
    "            out = fut.result()\n",
    "\n",
    "            valid_df.at[i, GATE_USED_COL] = out[\"gate_used\"]\n",
    "            valid_df.at[i, \"is_ambivalent_sa_domain\"] = out[\"is_ambivalent_sa_domain\"]\n",
    "            valid_df.at[i, \"op_author\"] = out[\"op_author\"]\n",
    "            valid_df.at[i, \"last_comment_depth\"] = out[\"last_comment_depth\"]\n",
    "            valid_df.at[i, \"last_comment_author\"] = out[\"last_comment_author\"]\n",
    "            valid_df.at[i, \"is_last_comment_by_op\"] = out[\"is_last_comment_by_op\"]\n",
    "\n",
    "            for lab, val in out[\"pred\"].items():\n",
    "                valid_df.at[i, lab] = val\n",
    "\n",
    "            valid_df.at[i, YES_LABEL_COL] = out[\"predicted_labels_yes\"]\n",
    "            valid_df.at[i, ERROR_COL] = out[\"error\"]\n",
    "\n",
    "        except Exception as e:\n",
    "            valid_df.at[i, ERROR_COL] = str(e)\n",
    "\n",
    "# Save once\n",
    "OUT_PATH = \"valid_with_predictions_o4mini.csv\"\n",
    "valid_df.to_csv(OUT_PATH, index=False)\n",
    "print(\"Saved:\", OUT_PATH)\n",
    "print(f\"Left existing 'Tags' untouched. Errors are in '{ERROR_COL}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bfc55bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 86\n",
      "predicted_labels_yes filled: 86\n",
      "llm_error filled: 0\n",
      "\n",
      "Top llm_error values:\n",
      "Series([], Name: count, dtype: int64)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tags</th>\n",
       "      <th>predicted_labels_yes</th>\n",
       "      <th>llm_error</th>\n",
       "      <th>is_ambivalent_sa_domain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Information support, Emotional support, Esteem...</td>\n",
       "      <td>Emotional support, Esteem support</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Group interactions</td>\n",
       "      <td>Seeking support</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>Not applicable</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>Not applicable</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Information support, Emotional support, Group ...</td>\n",
       "      <td>Information support, Emotional support</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>Not applicable</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Information support, Esteem support</td>\n",
       "      <td>Information support, Emotional support, Networ...</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Group interactions</td>\n",
       "      <td>Seeking support</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Information support, Emotional support</td>\n",
       "      <td>Information support, Emotional support</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Information support, Emotional support, Networ...</td>\n",
       "      <td>Information support, Emotional support, Networ...</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Tags  \\\n",
       "0  Information support, Emotional support, Esteem...   \n",
       "1                                 Group interactions   \n",
       "2                                     Not Applicable   \n",
       "3                                     Not Applicable   \n",
       "4  Information support, Emotional support, Group ...   \n",
       "5                                     Not Applicable   \n",
       "6                Information support, Esteem support   \n",
       "7                                 Group interactions   \n",
       "8             Information support, Emotional support   \n",
       "9  Information support, Emotional support, Networ...   \n",
       "\n",
       "                                predicted_labels_yes llm_error  \\\n",
       "0                  Emotional support, Esteem support      None   \n",
       "1                                    Seeking support      None   \n",
       "2                                     Not applicable      None   \n",
       "3                                     Not applicable      None   \n",
       "4             Information support, Emotional support      None   \n",
       "5                                     Not applicable      None   \n",
       "6  Information support, Emotional support, Networ...      None   \n",
       "7                                    Seeking support      None   \n",
       "8             Information support, Emotional support      None   \n",
       "9  Information support, Emotional support, Networ...      None   \n",
       "\n",
       "  is_ambivalent_sa_domain  \n",
       "0                    True  \n",
       "1                    True  \n",
       "2                    True  \n",
       "3                   False  \n",
       "4                    True  \n",
       "5                   False  \n",
       "6                    True  \n",
       "7                    True  \n",
       "8                    True  \n",
       "9                    True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Rows:\", len(valid_df))\n",
    "\n",
    "# how many rows got predictions\n",
    "if \"predicted_labels_yes\" in valid_df.columns:\n",
    "    print(\"predicted_labels_yes filled:\", valid_df[\"predicted_labels_yes\"].notna().sum())\n",
    "\n",
    "# how many rows errored\n",
    "if \"llm_error\" in valid_df.columns:\n",
    "    print(\"llm_error filled:\", valid_df[\"llm_error\"].notna().sum())\n",
    "    print(\"\\nTop llm_error values:\")\n",
    "    print(valid_df[\"llm_error\"].dropna().value_counts().head(10))\n",
    "\n",
    "# peek a few rows\n",
    "cols = [c for c in [\"Tags\", \"predicted_labels_yes\", \"llm_error\", \"is_ambivalent_sa_domain\"] if c in valid_df.columns]\n",
    "display(valid_df[cols].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7c98b49",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MultiLabelBinarizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m mlb = \u001b[43mMultiLabelBinarizer\u001b[49m(classes=ALL_LABELS)\n\u001b[32m      2\u001b[39m Y_true = mlb.fit_transform(y_true_list)\n\u001b[32m      3\u001b[39m Y_pred = mlb.transform(y_pred_list)\n",
      "\u001b[31mNameError\u001b[39m: name 'MultiLabelBinarizer' is not defined"
     ]
    }
   ],
   "source": [
    "mlb = MultiLabelBinarizer(classes=ALL_LABELS)\n",
    "Y_true = mlb.fit_transform(y_true_list)\n",
    "Y_pred = mlb.transform(y_pred_list)\n",
    "\n",
    "print(\"Is 'Seeking support' in classes?\", \"Seeking support\" in mlb.classes_)\n",
    "print(\"Classes:\", list(mlb.classes_))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b5f321e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: valid_with_predictions_4mini.csv\n",
      "Rows: 86\n",
      "Columns: ['post_id', 'parent_id', 'subreddit', 'comment_id', 'parent_fullname', 'depth', 'comment_author', 'comment_body', 'comment_score', 'created_utc', 'permalink', 'is_post_author', 'title', 'author', 'body', 'prompt', 'Tags', 'is_ambivalent_sa_domain', 'op_author', 'last_comment_depth', 'last_comment_author', 'is_last_comment_by_op', 'llm_error', 'predicted_labels_yes', 'gate_used', 'Information support', 'Emotional support', 'Esteem support', 'Network support', 'Tangible assistance', 'Seeking support', 'Group interactions', 'Not applicable']\n",
      "\n",
      "Empty ground-truth rows: 0\n",
      "Empty prediction rows: 2\n",
      "\n",
      "Overall Precision \\& Recall \\& F1\n",
      "micro_precision: 0.7606\n",
      "micro_recall: 0.7297\n",
      "micro_f1: 0.7448\n",
      "macro_precision: 0.6650\n",
      "macro_recall: 0.6792\n",
      "macro_f1: 0.6665\n",
      "samples_precision: 0.7068\n",
      "samples_recall: 0.6953\n",
      "samples_f1: 0.6863\n",
      "\n",
      "Per-label metrics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>support_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tangible assistance</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Information support</td>\n",
       "      <td>0.911111</td>\n",
       "      <td>0.759259</td>\n",
       "      <td>0.828283</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Emotional support</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Group interactions</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Not applicable</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Network support</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Esteem support</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.585366</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Seeking support</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 label  precision    recall        f1  support_true\n",
       "4  Tangible assistance   1.000000  1.000000  1.000000             2\n",
       "0  Information support   0.911111  0.759259  0.828283            54\n",
       "1    Emotional support   0.774194  0.888889  0.827586            27\n",
       "6   Group interactions   0.681818  0.750000  0.714286            20\n",
       "7       Not applicable   0.647059  0.785714  0.709677            14\n",
       "3      Network support   0.600000  0.750000  0.666667             4\n",
       "2       Esteem support   0.705882  0.500000  0.585366            24\n",
       "5      Seeking support   0.000000  0.000000  0.000000             3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "Information support       0.91      0.76      0.83        54\n",
      "  Emotional support       0.77      0.89      0.83        27\n",
      "     Esteem support       0.71      0.50      0.59        24\n",
      "    Network support       0.60      0.75      0.67         4\n",
      "Tangible assistance       1.00      1.00      1.00         2\n",
      "    Seeking support       0.00      0.00      0.00         3\n",
      " Group interactions       0.68      0.75      0.71        20\n",
      "     Not applicable       0.65      0.79      0.71        14\n",
      "\n",
      "          micro avg       0.76      0.73      0.74       148\n",
      "          macro avg       0.67      0.68      0.67       148\n",
      "       weighted avg       0.77      0.73      0.74       148\n",
      "        samples avg       0.71      0.70      0.69       148\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report, precision_recall_fscore_support\n",
    "\n",
    "# ====== 1) LOAD YOUR FILE ======\n",
    "IN_PATH = \"valid_with_predictions_4mini.csv\"\n",
    "df = pd.read_csv(IN_PATH)\n",
    "\n",
    "print(\"Loaded:\", IN_PATH)\n",
    "print(\"Rows:\", len(df))\n",
    "print(\"Columns:\", list(df.columns))\n",
    "\n",
    "# ====== 2) LABEL SET ======\n",
    "ALL_LABELS = [\n",
    "    \"Information support\",\n",
    "    \"Emotional support\",\n",
    "    \"Esteem support\",\n",
    "    \"Network support\",\n",
    "    \"Tangible assistance\",\n",
    "    \"Seeking support\",\n",
    "    \"Group interactions\",\n",
    "    \"Not applicable\",\n",
    "]\n",
    "LABEL_SET = set(ALL_LABELS)\n",
    "\n",
    "# map for case/spacing normalization\n",
    "_norm_map = {lab.lower().strip(): lab for lab in ALL_LABELS}\n",
    "\n",
    "def normalize_label(t: str) -> str | None:\n",
    "    t2 = str(t).strip()\n",
    "    if not t2:\n",
    "        return None\n",
    "    key = t2.lower().strip()\n",
    "    return _norm_map.get(key, None)  # returns canonical label or None if unknown\n",
    "\n",
    "# ====== 3) PARSE TAG STRINGS ======\n",
    "def parse_labels(x):\n",
    "    if x is None or (isinstance(x, float) and np.isnan(x)):\n",
    "        return []\n",
    "    s = str(x).strip()\n",
    "    if s == \"\" or s.lower() in {\"nan\", \"none\"}:\n",
    "        return []\n",
    "\n",
    "    labels = []\n",
    "\n",
    "    # Try JSON list\n",
    "    if s.startswith(\"[\") and s.endswith(\"]\"):\n",
    "        try:\n",
    "            obj = json.loads(s)\n",
    "            labels = [str(t).strip() for t in obj]\n",
    "        except Exception:\n",
    "            try:\n",
    "                obj = json.loads(re.sub(r\"'\", '\"', s))\n",
    "                labels = [str(t).strip() for t in obj]\n",
    "            except Exception:\n",
    "                labels = []\n",
    "\n",
    "    # Fallback split\n",
    "    if not labels:\n",
    "        parts = re.split(r\"[,\\n;|]+\", s)\n",
    "        labels = []\n",
    "        for t in parts:\n",
    "            t = re.sub(r\"^tags?\\s*:\\s*\", \"\", t.strip(), flags=re.IGNORECASE)\n",
    "            if t:\n",
    "                labels.append(t)\n",
    "\n",
    "    # Normalize + keep only known labels\n",
    "    out = []\n",
    "    for t in labels:\n",
    "        canon = normalize_label(t)\n",
    "        if canon is not None:\n",
    "            out.append(canon)\n",
    "    # de-dup while preserving order\n",
    "    seen = set()\n",
    "    out2 = []\n",
    "    for t in out:\n",
    "        if t not in seen:\n",
    "            seen.add(t)\n",
    "            out2.append(t)\n",
    "    return out2\n",
    "\n",
    "# ====== 4) BUILD y_true / y_pred ======\n",
    "assert \"Tags\" in df.columns, \"Missing ground-truth column: Tags\"\n",
    "assert \"predicted_labels_yes\" in df.columns, \"Missing prediction column: predicted_labels_yes\"\n",
    "\n",
    "y_true_list = df[\"Tags\"].apply(parse_labels).tolist()\n",
    "y_pred_list = df[\"predicted_labels_yes\"].apply(parse_labels).tolist()\n",
    "\n",
    "# (Optional) sanity check: how many rows have empty GT/pred after parsing?\n",
    "print(\"\\nEmpty ground-truth rows:\", sum(len(x)==0 for x in y_true_list))\n",
    "print(\"Empty prediction rows:\", sum(len(x)==0 for x in y_pred_list))\n",
    "\n",
    "mlb = MultiLabelBinarizer(classes=ALL_LABELS)\n",
    "Y_true = mlb.fit_transform(y_true_list)\n",
    "Y_pred = mlb.transform(y_pred_list)\n",
    "\n",
    "# ====== 5) OVERALL METRICS ======\n",
    "scores = {\n",
    "    \"micro_precision\": precision_score(Y_true, Y_pred, average=\"micro\", zero_division=0),\n",
    "    \"micro_recall\":    recall_score(Y_true, Y_pred, average=\"micro\", zero_division=0),\n",
    "    \"micro_f1\":        f1_score(Y_true, Y_pred, average=\"micro\", zero_division=0),\n",
    "\n",
    "    \"macro_precision\": precision_score(Y_true, Y_pred, average=\"macro\", zero_division=0),\n",
    "    \"macro_recall\":    recall_score(Y_true, Y_pred, average=\"macro\", zero_division=0),\n",
    "    \"macro_f1\":        f1_score(Y_true, Y_pred, average=\"macro\", zero_division=0),\n",
    "\n",
    "    \"samples_precision\": precision_score(Y_true, Y_pred, average=\"samples\", zero_division=0),\n",
    "    \"samples_recall\":    recall_score(Y_true, Y_pred, average=\"samples\", zero_division=0),\n",
    "    \"samples_f1\":        f1_score(Y_true, Y_pred, average=\"samples\", zero_division=0),\n",
    "}\n",
    "\n",
    "print(\"\\nOverall Precision \\\\& Recall \\\\& F1\")\n",
    "for k, v in scores.items():\n",
    "    print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "# ====== 6) PER-LABEL METRICS ======\n",
    "p, r, f1, support = precision_recall_fscore_support(Y_true, Y_pred, average=None, zero_division=0)\n",
    "\n",
    "per_label_df = pd.DataFrame({\n",
    "    \"label\": mlb.classes_,\n",
    "    \"precision\": p,\n",
    "    \"recall\": r,\n",
    "    \"f1\": f1,\n",
    "    \"support_true\": support\n",
    "}).sort_values(\"f1\", ascending=False)\n",
    "\n",
    "print(\"\\nPer-label metrics:\")\n",
    "display(per_label_df)\n",
    "\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(Y_true, Y_pred, target_names=mlb.classes_, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f2feb824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: valid_with_predictions_o4mini.csv\n",
      "Rows: 86\n",
      "Columns: ['post_id', 'parent_id', 'subreddit', 'comment_id', 'parent_fullname', 'depth', 'comment_author', 'comment_body', 'comment_score', 'created_utc', 'permalink', 'is_post_author', 'title', 'author', 'body', 'prompt', 'Tags', 'is_ambivalent_sa_domain', 'op_author', 'last_comment_depth', 'last_comment_author', 'is_last_comment_by_op', 'llm_error', 'predicted_labels_yes', 'gate_used', 'Information support', 'Emotional support', 'Esteem support', 'Network support', 'Tangible assistance', 'Seeking support', 'Group interactions', 'Not applicable']\n",
      "\n",
      "Empty ground-truth rows: 0\n",
      "Empty prediction rows: 75\n",
      "\n",
      "Overall Precision \\& Recall \\& F1\n",
      "micro_precision: 0.8182\n",
      "micro_recall: 0.0608\n",
      "micro_f1: 0.1132\n",
      "macro_precision: 0.2250\n",
      "macro_recall: 0.0737\n",
      "macro_f1: 0.0879\n",
      "samples_precision: 0.1047\n",
      "samples_recall: 0.1047\n",
      "samples_f1: 0.1047\n",
      "\n",
      "Per-label metrics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>support_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Not applicable</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Information support</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Esteem support</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Emotional support</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Network support</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tangible assistance</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Seeking support</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Group interactions</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 label  precision    recall        f1  support_true\n",
       "7       Not applicable        0.8  0.571429  0.666667            14\n",
       "0  Information support        1.0  0.018519  0.036364            54\n",
       "2       Esteem support        0.0  0.000000  0.000000            24\n",
       "1    Emotional support        0.0  0.000000  0.000000            27\n",
       "3      Network support        0.0  0.000000  0.000000             4\n",
       "4  Tangible assistance        0.0  0.000000  0.000000             2\n",
       "5      Seeking support        0.0  0.000000  0.000000             3\n",
       "6   Group interactions        0.0  0.000000  0.000000            20"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report:\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "Information support       1.00      0.02      0.04        54\n",
      "  Emotional support       0.00      0.00      0.00        27\n",
      "     Esteem support       0.00      0.00      0.00        24\n",
      "    Network support       0.00      0.00      0.00         4\n",
      "Tangible assistance       0.00      0.00      0.00         2\n",
      "    Seeking support       0.00      0.00      0.00         3\n",
      " Group interactions       0.00      0.00      0.00        20\n",
      "     Not applicable       0.80      0.57      0.67        14\n",
      "\n",
      "          micro avg       0.82      0.06      0.11       148\n",
      "          macro avg       0.23      0.07      0.09       148\n",
      "       weighted avg       0.44      0.06      0.08       148\n",
      "        samples avg       0.10      0.10      0.10       148\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, classification_report, precision_recall_fscore_support\n",
    "\n",
    "# ====== 1) LOAD YOUR FILE ======\n",
    "IN_PATH = \"valid_with_predictions_o4mini.csv\"\n",
    "df = pd.read_csv(IN_PATH)\n",
    "\n",
    "print(\"Loaded:\", IN_PATH)\n",
    "print(\"Rows:\", len(df))\n",
    "print(\"Columns:\", list(df.columns))\n",
    "\n",
    "# ====== 2) LABEL SET ======\n",
    "ALL_LABELS = [\n",
    "    \"Information support\",\n",
    "    \"Emotional support\",\n",
    "    \"Esteem support\",\n",
    "    \"Network support\",\n",
    "    \"Tangible assistance\",\n",
    "    \"Seeking support\",\n",
    "    \"Group interactions\",\n",
    "    \"Not applicable\",\n",
    "]\n",
    "LABEL_SET = set(ALL_LABELS)\n",
    "\n",
    "# map for case/spacing normalization\n",
    "_norm_map = {lab.lower().strip(): lab for lab in ALL_LABELS}\n",
    "\n",
    "def normalize_label(t: str) -> str | None:\n",
    "    t2 = str(t).strip()\n",
    "    if not t2:\n",
    "        return None\n",
    "    key = t2.lower().strip()\n",
    "    return _norm_map.get(key, None)  # returns canonical label or None if unknown\n",
    "\n",
    "# ====== 3) PARSE TAG STRINGS ======\n",
    "def parse_labels(x):\n",
    "    if x is None or (isinstance(x, float) and np.isnan(x)):\n",
    "        return []\n",
    "    s = str(x).strip()\n",
    "    if s == \"\" or s.lower() in {\"nan\", \"none\"}:\n",
    "        return []\n",
    "\n",
    "    labels = []\n",
    "\n",
    "    # Try JSON list\n",
    "    if s.startswith(\"[\") and s.endswith(\"]\"):\n",
    "        try:\n",
    "            obj = json.loads(s)\n",
    "            labels = [str(t).strip() for t in obj]\n",
    "        except Exception:\n",
    "            try:\n",
    "                obj = json.loads(re.sub(r\"'\", '\"', s))\n",
    "                labels = [str(t).strip() for t in obj]\n",
    "            except Exception:\n",
    "                labels = []\n",
    "\n",
    "    # Fallback split\n",
    "    if not labels:\n",
    "        parts = re.split(r\"[,\\n;|]+\", s)\n",
    "        labels = []\n",
    "        for t in parts:\n",
    "            t = re.sub(r\"^tags?\\s*:\\s*\", \"\", t.strip(), flags=re.IGNORECASE)\n",
    "            if t:\n",
    "                labels.append(t)\n",
    "\n",
    "    # Normalize + keep only known labels\n",
    "    out = []\n",
    "    for t in labels:\n",
    "        canon = normalize_label(t)\n",
    "        if canon is not None:\n",
    "            out.append(canon)\n",
    "    # de-dup while preserving order\n",
    "    seen = set()\n",
    "    out2 = []\n",
    "    for t in out:\n",
    "        if t not in seen:\n",
    "            seen.add(t)\n",
    "            out2.append(t)\n",
    "    return out2\n",
    "\n",
    "# ====== 4) BUILD y_true / y_pred ======\n",
    "assert \"Tags\" in df.columns, \"Missing ground-truth column: Tags\"\n",
    "assert \"predicted_labels_yes\" in df.columns, \"Missing prediction column: predicted_labels_yes\"\n",
    "\n",
    "y_true_list = df[\"Tags\"].apply(parse_labels).tolist()\n",
    "y_pred_list = df[\"predicted_labels_yes\"].apply(parse_labels).tolist()\n",
    "\n",
    "# (Optional) sanity check: how many rows have empty GT/pred after parsing?\n",
    "print(\"\\nEmpty ground-truth rows:\", sum(len(x)==0 for x in y_true_list))\n",
    "print(\"Empty prediction rows:\", sum(len(x)==0 for x in y_pred_list))\n",
    "\n",
    "mlb = MultiLabelBinarizer(classes=ALL_LABELS)\n",
    "Y_true = mlb.fit_transform(y_true_list)\n",
    "Y_pred = mlb.transform(y_pred_list)\n",
    "\n",
    "# ====== 5) OVERALL METRICS ======\n",
    "scores = {\n",
    "    \"micro_precision\": precision_score(Y_true, Y_pred, average=\"micro\", zero_division=0),\n",
    "    \"micro_recall\":    recall_score(Y_true, Y_pred, average=\"micro\", zero_division=0),\n",
    "    \"micro_f1\":        f1_score(Y_true, Y_pred, average=\"micro\", zero_division=0),\n",
    "\n",
    "    \"macro_precision\": precision_score(Y_true, Y_pred, average=\"macro\", zero_division=0),\n",
    "    \"macro_recall\":    recall_score(Y_true, Y_pred, average=\"macro\", zero_division=0),\n",
    "    \"macro_f1\":        f1_score(Y_true, Y_pred, average=\"macro\", zero_division=0),\n",
    "\n",
    "    \"samples_precision\": precision_score(Y_true, Y_pred, average=\"samples\", zero_division=0),\n",
    "    \"samples_recall\":    recall_score(Y_true, Y_pred, average=\"samples\", zero_division=0),\n",
    "    \"samples_f1\":        f1_score(Y_true, Y_pred, average=\"samples\", zero_division=0),\n",
    "}\n",
    "\n",
    "print(\"\\nOverall Precision \\\\& Recall \\\\& F1\")\n",
    "for k, v in scores.items():\n",
    "    print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "# ====== 6) PER-LABEL METRICS ======\n",
    "p, r, f1, support = precision_recall_fscore_support(Y_true, Y_pred, average=None, zero_division=0)\n",
    "\n",
    "per_label_df = pd.DataFrame({\n",
    "    \"label\": mlb.classes_,\n",
    "    \"precision\": p,\n",
    "    \"recall\": r,\n",
    "    \"f1\": f1,\n",
    "    \"support_true\": support\n",
    "}).sort_values(\"f1\", ascending=False)\n",
    "\n",
    "print(\"\\nPer-label metrics:\")\n",
    "display(per_label_df)\n",
    "\n",
    "print(\"\\nClassification report:\")\n",
    "print(classification_report(Y_true, Y_pred, target_names=mlb.classes_, zero_division=0))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
