{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fbc0304",
   "metadata": {},
   "source": [
    "# Support Multi-Label Pipeline (3-Step)\n",
    "This notebook:\n",
    "1) Loads `train.csv` (14 rows) to build few-shot examples  \n",
    "2) Loads `valid.csv` (86 rows) to predict labels  \n",
    "3) Runs 3 gates: Domain Gate ‚Üí OP Last Comment Gate ‚Üí Final Multi-label  \n",
    "4) Saves `valid_with_predictions.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd63ab61",
   "metadata": {},
   "source": [
    "## 1. Project Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ee760aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: openai in /home/ec2-user/.local/lib/python3.11/site-packages (2.14.0)\n",
      "Requirement already satisfied: python-dotenv in /home/ec2-user/.local/lib/python3.11/site-packages (1.2.1)\n",
      "Requirement already satisfied: pandas in /home/ec2-user/.local/lib/python3.11/site-packages (2.3.3)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/.local/lib/python3.11/site-packages (4.67.1)\n",
      "Requirement already satisfied: pydantic in /home/ec2-user/.local/lib/python3.11/site-packages (2.12.5)\n",
      "Requirement already satisfied: scikit-learn in /home/ec2-user/.local/lib/python3.11/site-packages (1.8.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/ec2-user/.local/lib/python3.11/site-packages (from openai) (4.12.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /home/ec2-user/.local/lib/python3.11/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/ec2-user/.local/lib/python3.11/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /home/ec2-user/.local/lib/python3.11/site-packages (from openai) (0.12.0)\n",
      "Requirement already satisfied: sniffio in /home/ec2-user/.local/lib/python3.11/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /home/ec2-user/.local/lib/python3.11/site-packages (from openai) (4.15.0)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /home/ec2-user/.local/lib/python3.11/site-packages (from pandas) (2.3.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/ec2-user/.local/lib/python3.11/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/.local/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/ec2-user/.local/lib/python3.11/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ec2-user/.local/lib/python3.11/site-packages (from pydantic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in /home/ec2-user/.local/lib/python3.11/site-packages (from pydantic) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /home/ec2-user/.local/lib/python3.11/site-packages (from pydantic) (0.4.2)\n",
      "Requirement already satisfied: scipy>=1.10.0 in /home/ec2-user/.local/lib/python3.11/site-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.3.0 in /home/ec2-user/.local/lib/python3.11/site-packages (from scikit-learn) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in /home/ec2-user/.local/lib/python3.11/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: idna>=2.8 in /home/ec2-user/.local/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai) (3.11)\n",
      "Requirement already satisfied: certifi in /home/ec2-user/.local/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /home/ec2-user/.local/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /home/ec2-user/.local/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/.local/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U openai python-dotenv pandas tqdm pydantic scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f8977e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=\"https://router.huggingface.co/v1\",\n",
    "    api_key=os.getenv(\"HF_TOKEN\"),\n",
    ")\n",
    "\n",
    "MODEL = \"openai/gpt-oss-120b:cerebras\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46d0dd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, time\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel\n",
    "from typing_extensions import Literal\n",
    "from openai import OpenAI\n",
    "\n",
    "# load_dotenv()\n",
    "# assert os.getenv(\"OPENAI_API_KEY\"), \"OPENAI_API_KEY not found in environment or .env\"\n",
    "\n",
    "# client = OpenAI()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73ed77d",
   "metadata": {},
   "source": [
    "## 2. Loading files and definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2a41eda0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>parent_id</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>parent_fullname</th>\n",
       "      <th>depth</th>\n",
       "      <th>comment_author</th>\n",
       "      <th>comment_body</th>\n",
       "      <th>comment_score</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>...</th>\n",
       "      <th>body</th>\n",
       "      <th>prompt</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Information support</th>\n",
       "      <th>Emotional support</th>\n",
       "      <th>Esteem support</th>\n",
       "      <th>Network support</th>\n",
       "      <th>Tangible assistance</th>\n",
       "      <th>Seeking support</th>\n",
       "      <th>Group interactions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1lc7y2n</td>\n",
       "      <td>NaN</td>\n",
       "      <td>TooAfraidToAsk</td>\n",
       "      <td>mxysa7g</td>\n",
       "      <td>t3_1lc7y2n</td>\n",
       "      <td>0</td>\n",
       "      <td>Miaous95</td>\n",
       "      <td>Definitely SA and I‚Äôd do it back to him see if...</td>\n",
       "      <td>5</td>\n",
       "      <td>1750018747</td>\n",
       "      <td>...</td>\n",
       "      <td>So you have sex with a man with consent. You b...</td>\n",
       "      <td>Original Post:\\nAuthor: Beginning_Exit_6256\\nT...</td>\n",
       "      <td>Information support</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5rf97b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>relationship_advice</td>\n",
       "      <td>dd7kbxy</td>\n",
       "      <td>t3_5rf97b</td>\n",
       "      <td>0</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>You cheated on him. You are responsible for yo...</td>\n",
       "      <td>5</td>\n",
       "      <td>1485988490</td>\n",
       "      <td>...</td>\n",
       "      <td>My boyfriend (17/m) and I had been dating for ...</td>\n",
       "      <td>Original Post:\\nAuthor: ahhhhconfuse\\nTitle: D...</td>\n",
       "      <td>Information support</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows √ó 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id parent_id            subreddit comment_id parent_fullname  depth  \\\n",
       "0  1lc7y2n       NaN       TooAfraidToAsk    mxysa7g      t3_1lc7y2n      0   \n",
       "1   5rf97b       NaN  relationship_advice    dd7kbxy       t3_5rf97b      0   \n",
       "\n",
       "  comment_author                                       comment_body  \\\n",
       "0       Miaous95  Definitely SA and I‚Äôd do it back to him see if...   \n",
       "1      [deleted]  You cheated on him. You are responsible for yo...   \n",
       "\n",
       "   comment_score  created_utc  ...  \\\n",
       "0              5   1750018747  ...   \n",
       "1              5   1485988490  ...   \n",
       "\n",
       "                                                body  \\\n",
       "0  So you have sex with a man with consent. You b...   \n",
       "1  My boyfriend (17/m) and I had been dating for ...   \n",
       "\n",
       "                                              prompt                 Tags  \\\n",
       "0  Original Post:\\nAuthor: Beginning_Exit_6256\\nT...  Information support   \n",
       "1  Original Post:\\nAuthor: ahhhhconfuse\\nTitle: D...  Information support   \n",
       "\n",
       "  Information support Emotional support Esteem support Network support  \\\n",
       "0                 Yes                No             No              No   \n",
       "1                 Yes                No             No              No   \n",
       "\n",
       "  Tangible assistance Seeking support Group interactions  \n",
       "0                  No              No                 No  \n",
       "1                  No              No                 No  \n",
       "\n",
       "[2 rows x 24 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_PATH = \"../../data/train.csv\"\n",
    "VALID_PATH = \"../../data/valid_86.csv\"\n",
    "\n",
    "train_df = pd.read_csv(TRAIN_PATH)\n",
    "valid_df = pd.read_csv(VALID_PATH)\n",
    "\n",
    "assert \"prompt\" in train_df.columns, \"train.csv must contain a 'prompt' column\"\n",
    "assert \"prompt\" in valid_df.columns, \"valid.csv must contain a 'prompt' column\"\n",
    "\n",
    "train_df[\"prompt\"] = train_df[\"prompt\"].fillna(\"\").astype(str)\n",
    "valid_df[\"prompt\"] = valid_df[\"prompt\"].fillna(\"\").astype(str)\n",
    "\n",
    "train_df.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ff3fd74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = [\n",
    "    \"Information support\",\n",
    "    \"Emotional support\",\n",
    "    \"Esteem support\",\n",
    "    \"Network support\",\n",
    "    \"Tangible assistance\",\n",
    "    \"Seeking support\",\n",
    "    \"Group interactions\",\n",
    "    \"Not applicable\",\n",
    "]\n",
    "\n",
    "SUPPORT_ONLY_LABELS = [\n",
    "    \"Information support\",\n",
    "    \"Emotional support\",\n",
    "    \"Esteem support\",\n",
    "    \"Network support\",\n",
    "    \"Tangible assistance\",\n",
    "    \"Seeking support\",\n",
    "    \"Group interactions\",\n",
    "]\n",
    "\n",
    "SUPPORT_DEFINITIONS = \"\"\"\n",
    "Information support: Giving advice, facts, resources, or explanations that clarify what‚Äôs happening or what to do (including opinionated judgments like ‚Äúthat is assault‚Äù when used to inform/guide).\n",
    "Emotional support: Messages that express care and empathy‚Äîcomforting, showing affection/sympathy, encouraging hope, offering prayers, or easing guilt/blame (‚ÄúI‚Äôm so sorry,‚Äù ‚Äúsending hugs,‚Äù ‚Äústay strong,‚Äù ‚ÄúI‚Äôll pray for you,‚Äù ‚Äúit‚Äôs not your fault‚Äù).\n",
    "Esteem support: Messages that build the user up by complimenting them or validating their feelings/beliefs/actions as reasonable/normal.\n",
    "Network support: Encouraging the person to reach out to other people or connect with external help systems (therapy, friends, family, communities, etc.). Note : Suggesting to go to police is Information support and not Network support.\n",
    "Tangible assistance: When the commenter personally offers to help directly (I am here, You can talk to me).\n",
    "Seeking support: Messages where the author explicitly asks for help for themselves‚Äîeither a direct question/request for info/suggestions or an explicit reassurance request.\n",
    "Group interactions: Any reply that primarily participates socially in the thread‚Äîexpressing gratitude/thanks, congratulations, or sharing one‚Äôs own experience/story (including ‚Äúme too‚Äù anecdotes). This label can co-occur with other support labels if the comment also gives advice, empathy, or info.\n",
    "\"\"\".strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2ebab603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information support: YES count = 2\n",
      "Emotional support: YES count = 2\n",
      "Esteem support: YES count = 2\n",
      "Network support: YES count = 2\n",
      "Tangible assistance: YES count = 2\n",
      "Seeking support: YES count = 0\n",
      "Group interactions: YES count = 2\n"
     ]
    }
   ],
   "source": [
    "for lab in SUPPORT_ONLY_LABELS:\n",
    "    if lab not in train_df.columns:\n",
    "        print(f\"‚ùå Missing column: {lab}\")\n",
    "    else:\n",
    "        yes_count = (train_df[lab].astype(str).str.strip().str.lower() == \"yes\").sum()\n",
    "        print(f\"{lab}: YES count = {yes_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c934e56f",
   "metadata": {},
   "source": [
    "## 3. Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8a20a634",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOMAIN_GATE_PROMPT = \"\"\"\n",
    "You are a psychologist and an expert in Reddit threads about possible sexual harassment/sexual assault.\n",
    "\n",
    "Task: DOMAIN GATE.\n",
    "\n",
    "Decide if the author is UNCERTAIN about whether the experience counts as sexual assault/harassment.\n",
    "\n",
    "Return true ONLY if the author explicitly questions whether the experience counts as SA/harassment.\n",
    "\n",
    "Return false otherwise.\n",
    "\n",
    "Return ONLY valid JSON:\n",
    "{{\n",
    "  \"is_ambivalent_sa_domain\": true/false\n",
    "}}\n",
    "\n",
    "Prompt:\n",
    "{prompt_text}\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "OP_LAST_COMMENT_PROMPT = \"\"\"\n",
    "Input format:\n",
    "- There is an \"Original Post:\" section with Author, Title, Body.\n",
    "- There is a \"Conversation History:\" section with a single/multiple comments.\n",
    "\"Conversation History:\" includes blocks like:\n",
    "  Comment (depth X):\n",
    "  Author: ... \n",
    "  Content: ...\n",
    "\n",
    "Steps:\n",
    "1) Extract OP from \"Original Post: Author:\"\n",
    "2) Choose the comment with the highest depth in the conversation history.\n",
    "3) Extract that last comment's Author, Depth, and Content.\n",
    "4) Compare last comment author with OP.\n",
    "\n",
    "Return ONLY valid JSON:\n",
    "{{\n",
    "  \"op_author\": \"<string>\",\n",
    "  \"last_comment_depth\": <int>,\n",
    "  \"last_comment_author\": \"<string>\",\n",
    "  \"last_comment_content\": \"<string>\",\n",
    "  \"is_last_comment_by_op\": true/false\n",
    "}}\n",
    "\n",
    "Prompt:\n",
    "{prompt_text}\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "FINAL_MULTILABEL_PROMPT = \"\"\"\n",
    "You are a psychologist expert in identifying support in Reddit comments. \n",
    "\n",
    "You will label ONLY this comment (the last comment in the thread):\n",
    "Last Comment Author: {last_comment_author}\n",
    "Last Comment Content: {last_comment_content}\n",
    "\n",
    "Gates (already computed):\n",
    "- is_ambivalent_sa_domain: {is_ambivalent_sa_domain}\n",
    "- is_last_comment_by_op: {is_last_comment_by_op}\n",
    "\n",
    "Rules:\n",
    "1) If is_ambivalent_sa_domain is false:\n",
    "   - Output: Not applicable = YES, and all other labels = NO. Stop.\n",
    "\n",
    "2) If is_last_comment_by_op is true:\n",
    "   - Only evaluate: Seeking support.\n",
    "   - Force: Information support/Emotional support/Esteem support/Network support/Tangible assistance = NO.\n",
    "   - Default rule:\n",
    "     * If Seeking support = NO, then Group interactions = YES.\n",
    "     * Else evaluate Group interactions.\n",
    "\n",
    "                \n",
    "3) Otherwise:\n",
    "   - Only evaluate: Information support, Emotional support, Esteem support, Network support, Tangible assistance, Group interactions.\n",
    "   - Force: Seeking support = NO.\n",
    "   - Not applicable = YES only if all evaluated labels are NO.\n",
    "\n",
    "Definitions:\n",
    "{support_definitions}\n",
    "\n",
    "Few-shot examples:\n",
    "{few_shot_examples}\n",
    "\n",
    "Return ONLY valid JSON with all labels:\n",
    "{{\n",
    "  \"Information support\": \"YES/NO\",\n",
    "  \"Emotional support\": \"YES/NO\",\n",
    "  \"Esteem support\": \"YES/NO\",\n",
    "  \"Network support\": \"YES/NO\",\n",
    "  \"Tangible assistance\": \"YES/NO\",\n",
    "  \"Seeking support\": \"YES/NO\",\n",
    "  \"Group interactions\": \"YES/NO\",\n",
    "  \"Not applicable\": \"YES/NO\"\n",
    "}}\n",
    "\n",
    "Prompt:\n",
    "{prompt_text}\n",
    "\"\"\".strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0a77ff79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_title_body(full_prompt: str):\n",
    "    if not full_prompt or not isinstance(full_prompt, str):\n",
    "        return \"\", \"\"\n",
    "    title_m = re.search(r\"Title:\\s*(.*)\", full_prompt)\n",
    "    body_m  = re.search(r\"Body:\\s*(.*?)(?:\\n---\\n|Conversation History:|\\Z)\", full_prompt, flags=re.DOTALL)\n",
    "    title = title_m.group(1).strip() if title_m else \"\"\n",
    "    body  = body_m.group(1).strip() if body_m else \"\"\n",
    "    return title, body\n",
    "\n",
    "def build_gate_title_only(full_prompt: str) -> str:\n",
    "    title, _ = extract_title_body(full_prompt)\n",
    "    return f\"\"\"Original Post:\n",
    "Title: {title}\n",
    "\"\"\".strip()\n",
    "\n",
    "def build_gate_full_op(full_prompt: str) -> str:\n",
    "    title, body = extract_title_body(full_prompt)\n",
    "    return f\"\"\"Original Post:\n",
    "Title: {title}\n",
    "Body: {body}\n",
    "\"\"\".strip()\n",
    "\n",
    "def domain_gate_title_then_fullbody(model: str, full_prompt: str):\n",
    "    \"\"\"\n",
    "    Gate 1: Title-only\n",
    "    If false -> Gate 2: Title + full Body (no comments)\n",
    "    \"\"\"\n",
    "    gate1_text = build_gate_title_only(full_prompt)\n",
    "    dg1 = call_structured(model, DOMAIN_GATE_PROMPT.format(prompt_text=gate1_text), DomainGateOut)\n",
    "    if dg1.is_ambivalent_sa_domain:\n",
    "        return dg1, \"title_only\"\n",
    "\n",
    "    gate2_text = build_gate_full_op(full_prompt)\n",
    "    dg2 = call_structured(model, DOMAIN_GATE_PROMPT.format(prompt_text=gate2_text), DomainGateOut)\n",
    "    return dg2, \"full_body_fallback\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a597086f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field, ConfigDict\n",
    "from typing_extensions import Literal\n",
    "\n",
    "class DomainGateOut(BaseModel):\n",
    "    is_ambivalent_sa_domain: bool\n",
    "\n",
    "class LastCommentOut(BaseModel):\n",
    "    op_author: str\n",
    "    last_comment_depth: int\n",
    "    last_comment_author: str\n",
    "    last_comment_content: str\n",
    "    is_last_comment_by_op: bool\n",
    "\n",
    "YesNo = Literal[\"YES\", \"NO\"]\n",
    "\n",
    "class MultiLabelOut(BaseModel):\n",
    "    model_config = ConfigDict(populate_by_name=True)\n",
    "\n",
    "    Information_support: YesNo = Field(alias=\"Information support\")\n",
    "    Emotional_support: YesNo = Field(alias=\"Emotional support\")\n",
    "    Esteem_support: YesNo = Field(alias=\"Esteem support\")\n",
    "    Network_support: YesNo = Field(alias=\"Network support\")\n",
    "    Tangible_assistance: YesNo = Field(alias=\"Tangible assistance\")\n",
    "    Seeking_support: YesNo = Field(alias=\"Seeking support\")\n",
    "    Group_interactions: YesNo = Field(alias=\"Group interactions\")\n",
    "    Not_applicable: YesNo = Field(alias=\"Not applicable\")\n",
    "\n",
    "    def to_label_dict(self):\n",
    "        return {\n",
    "            \"Information support\": self.Information_support,\n",
    "            \"Emotional support\": self.Emotional_support,\n",
    "            \"Esteem support\": self.Esteem_support,\n",
    "            \"Network support\": self.Network_support,\n",
    "            \"Tangible assistance\": self.Tangible_assistance,\n",
    "            \"Seeking support\": self.Seeking_support,\n",
    "            \"Group interactions\": self.Group_interactions,\n",
    "            \"Not applicable\": self.Not_applicable,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0de256",
   "metadata": {},
   "source": [
    "## 4. OpenAI Call Helper (Structured Parse) + Build examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "797ca47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, re, time\n",
    "\n",
    "def _get_choice_text(choice) -> str | None:\n",
    "    \"\"\"\n",
    "    HF router providers sometimes return text in different fields.\n",
    "    Try the common ones safely.\n",
    "    \"\"\"\n",
    "    # 1) Standard OpenAI chat format\n",
    "    msg = getattr(choice, \"message\", None)\n",
    "    if msg is not None:\n",
    "        content = getattr(msg, \"content\", None)\n",
    "\n",
    "        # content can be a normal string\n",
    "        if isinstance(content, str) and content.strip():\n",
    "            return content\n",
    "\n",
    "        # sometimes content is a list of parts (rare, provider-dependent)\n",
    "        if isinstance(content, list):\n",
    "            parts = []\n",
    "            for p in content:\n",
    "                if isinstance(p, dict):\n",
    "                    # common shapes: {\"type\":\"text\",\"text\":\"...\"} or {\"text\":\"...\"}\n",
    "                    if p.get(\"type\") == \"text\" and isinstance(p.get(\"text\"), str):\n",
    "                        parts.append(p[\"text\"])\n",
    "                    elif isinstance(p.get(\"text\"), str):\n",
    "                        parts.append(p[\"text\"])\n",
    "            joined = \"\".join(parts).strip()\n",
    "            if joined:\n",
    "                return joined\n",
    "\n",
    "    # 2) Legacy completion-style\n",
    "    txt = getattr(choice, \"text\", None)\n",
    "    if isinstance(txt, str) and txt.strip():\n",
    "        return txt\n",
    "\n",
    "    return None\n",
    "\n",
    "def _extract_first_json_obj(text: str) -> str:\n",
    "    text = text.strip()\n",
    "    if text.startswith(\"{\") and text.endswith(\"}\"):\n",
    "        return text\n",
    "    m = re.search(r\"\\{.*\\}\", text, flags=re.DOTALL)\n",
    "    if not m:\n",
    "        raise ValueError(f\"No JSON object found in model output. First 400 chars:\\n{text[:400]}\")\n",
    "    return m.group(0)\n",
    "\n",
    "def call_structured(model: str, prompt: str, out_schema, max_retries: int = 6):\n",
    "    last_err = None\n",
    "\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            resp = client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                temperature=0.2,\n",
    "                max_tokens=900,\n",
    "            )\n",
    "\n",
    "            choice0 = resp.choices[0]\n",
    "            txt = _get_choice_text(choice0)\n",
    "\n",
    "            if not txt:\n",
    "                # Print debug once; this is usually not recoverable by retrying\n",
    "                print(\"DEBUG: Empty/None content returned.\")\n",
    "                try:\n",
    "                    print(\"finish_reason:\", getattr(choice0, \"finish_reason\", None))\n",
    "                    print(\"choice0:\", choice0)\n",
    "                except Exception:\n",
    "                    pass\n",
    "                raise ValueError(\"Model returned no text content (None/empty).\")\n",
    "\n",
    "            json_str = _extract_first_json_obj(txt)\n",
    "            data = json.loads(json_str)\n",
    "\n",
    "            # Pydantic v2\n",
    "            if hasattr(out_schema, \"model_validate\"):\n",
    "                return out_schema.model_validate(data)\n",
    "            # Pydantic v1 fallback\n",
    "            return out_schema(**data)\n",
    "\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "            sleep_s = min(8.0, 0.75 * (1.5 ** attempt))\n",
    "            print(f\"[retry {attempt+1}/{max_retries}] {type(e).__name__}: sleeping {sleep_s:.2f}s\")\n",
    "            time.sleep(sleep_s)\n",
    "\n",
    "    raise RuntimeError(f\"HF call failed after retries. Last error: {last_err}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f7b76cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: label 'Seeking support' has only 0 YES rows\n",
      "Example 1:\n",
      "Prompt:\n",
      "Original Post:\n",
      "Author: Beginning_Exit_6256\n",
      "Title: Is this considered sexual assault?\n",
      "Body: So you have sex with a man with consent. You both want to have sex. You tell him that you don‚Äôt swallow semen and you‚Äôve never done that. He tells you to do it but you don‚Äôt\n",
      "\n",
      "He then thinks it‚Äôs funny/as a joke to force some of his semen with his hand in your mouth? He forcibly does this with his hand\n",
      "\n",
      "Is this sexual assault?\n",
      "\n",
      "edit: he‚Äôd probably just get arrested for that. I don‚Äôt he‚Äôd go to prison for it though lol\n",
      "\n",
      "---\n",
      "Conversation History:\n",
      "Comment (depth 0):\n",
      "Author: Miaous95\n",
      "Content: Definitely SA and I‚Äôd do it back to him see if he finds it funny\n",
      "\n",
      "Gold labels (JSON):\n",
      "{\"Information support\": \"YES\", \"Emotional support\": \"NO\", \"Esteem support\": \"NO\", \"Network support\": \"NO\", \"Tangible assistance\": \"NO\", \"Seeking support\": \"NO\", \"Group interactions\": \"NO\", \"Not applicable\": \"NO\"}\n",
      "\n",
      "\n",
      "Example 2:\n",
      "Prompt:\n",
      "Original Post:\n",
      "Author: ahhhhconfuse\n",
      "Title: Did I (17/f) cheat on my boyfriend or was I sexually assaulted?\n",
      "Body: My boyfriend (17/m) and I had been dating for a year, and we really loved each other. There was nothing about him I disliked and I really enjoyed being in this rela\n"
     ]
    }
   ],
   "source": [
    "def build_few_shot_examples(train_df: pd.DataFrame) -> str:\n",
    "    missing = [lab for lab in SUPPORT_ONLY_LABELS if lab not in train_df.columns]\n",
    "    if missing:\n",
    "        print(\"‚ùå Missing label columns:\", missing)\n",
    "        return \"NO_FEW_SHOT_AVAILABLE\"\n",
    "\n",
    "    blocks = []\n",
    "    idx = 1\n",
    "\n",
    "    for lab in SUPPORT_ONLY_LABELS:\n",
    "        positives = train_df[train_df[lab].astype(str).str.strip().str.lower().eq(\"yes\")].head(2)\n",
    "        if len(positives) < 2:\n",
    "            print(f\"WARNING: label '{lab}' has only {len(positives)} YES rows\")\n",
    "\n",
    "        for _, row in positives.iterrows():\n",
    "            gold = {c: \"NO\" for c in LABELS}\n",
    "            for c in LABELS:\n",
    "                if c in train_df.columns:\n",
    "                    gold[c] = str(row.get(c, \"NO\")).strip().upper()\n",
    "\n",
    "            if \"Not applicable\" not in train_df.columns:\n",
    "                gold[\"Not applicable\"] = \"YES\" if all(gold[x] == \"NO\" for x in SUPPORT_ONLY_LABELS) else \"NO\"\n",
    "\n",
    "            blocks.append(\n",
    "                f\"Example {idx}:\\n\"\n",
    "                f\"Prompt:\\n{row['prompt']}\\n\\n\"\n",
    "                f\"Gold labels (JSON):\\n{json.dumps(gold, ensure_ascii=False)}\\n\"\n",
    "            )\n",
    "            idx += 1\n",
    "\n",
    "    return \"\\n\\n\".join(blocks).strip()\n",
    "\n",
    "few_shot_examples = build_few_shot_examples(train_df)\n",
    "print(few_shot_examples[:1200])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e88380",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9cc1c23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total models visible: 114\n",
      "\n",
      "babbage-002\n",
      "chatgpt-4o-latest\n",
      "chatgpt-image-latest\n",
      "codex-mini-latest\n",
      "dall-e-2\n",
      "dall-e-3\n",
      "davinci-002\n",
      "gpt-3.5-turbo\n",
      "gpt-3.5-turbo-0125\n",
      "gpt-3.5-turbo-1106\n",
      "gpt-3.5-turbo-16k\n",
      "gpt-3.5-turbo-instruct\n",
      "gpt-3.5-turbo-instruct-0914\n",
      "gpt-4\n",
      "gpt-4-0125-preview\n",
      "gpt-4-0613\n",
      "gpt-4-1106-preview\n",
      "gpt-4-turbo\n",
      "gpt-4-turbo-2024-04-09\n",
      "gpt-4-turbo-preview\n",
      "gpt-4.1\n",
      "gpt-4.1-2025-04-14\n",
      "gpt-4.1-mini\n",
      "gpt-4.1-mini-2025-04-14\n",
      "gpt-4.1-nano\n",
      "gpt-4.1-nano-2025-04-14\n",
      "gpt-4o\n",
      "gpt-4o-2024-05-13\n",
      "gpt-4o-2024-08-06\n",
      "gpt-4o-2024-11-20\n",
      "gpt-4o-audio-preview\n",
      "gpt-4o-audio-preview-2024-12-17\n",
      "gpt-4o-audio-preview-2025-06-03\n",
      "gpt-4o-mini\n",
      "gpt-4o-mini-2024-07-18\n",
      "gpt-4o-mini-audio-preview\n",
      "gpt-4o-mini-audio-preview-2024-12-17\n",
      "gpt-4o-mini-realtime-preview\n",
      "gpt-4o-mini-realtime-preview-2024-12-17\n",
      "gpt-4o-mini-search-preview\n",
      "gpt-4o-mini-search-preview-2025-03-11\n",
      "gpt-4o-mini-transcribe\n",
      "gpt-4o-mini-transcribe-2025-03-20\n",
      "gpt-4o-mini-transcribe-2025-12-15\n",
      "gpt-4o-mini-tts\n",
      "gpt-4o-mini-tts-2025-03-20\n",
      "gpt-4o-mini-tts-2025-12-15\n",
      "gpt-4o-realtime-preview\n",
      "gpt-4o-realtime-preview-2024-12-17\n",
      "gpt-4o-realtime-preview-2025-06-03\n",
      "gpt-4o-search-preview\n",
      "gpt-4o-search-preview-2025-03-11\n",
      "gpt-4o-transcribe\n",
      "gpt-4o-transcribe-diarize\n",
      "gpt-5\n",
      "gpt-5-2025-08-07\n",
      "gpt-5-chat-latest\n",
      "gpt-5-codex\n",
      "gpt-5-mini\n",
      "gpt-5-mini-2025-08-07\n",
      "gpt-5-nano\n",
      "gpt-5-nano-2025-08-07\n",
      "gpt-5-pro\n",
      "gpt-5-pro-2025-10-06\n",
      "gpt-5-search-api\n",
      "gpt-5-search-api-2025-10-14\n",
      "gpt-5.1\n",
      "gpt-5.1-2025-11-13\n",
      "gpt-5.1-chat-latest\n",
      "gpt-5.1-codex\n",
      "gpt-5.1-codex-max\n",
      "gpt-5.1-codex-mini\n",
      "gpt-5.2\n",
      "gpt-5.2-2025-12-11\n",
      "gpt-5.2-chat-latest\n",
      "gpt-5.2-pro\n",
      "gpt-5.2-pro-2025-12-11\n",
      "gpt-audio\n",
      "gpt-audio-2025-08-28\n",
      "gpt-audio-mini\n",
      "gpt-audio-mini-2025-10-06\n",
      "gpt-audio-mini-2025-12-15\n",
      "gpt-image-1\n",
      "gpt-image-1-mini\n",
      "gpt-image-1.5\n",
      "gpt-realtime\n",
      "gpt-realtime-2025-08-28\n",
      "gpt-realtime-mini\n",
      "gpt-realtime-mini-2025-10-06\n",
      "gpt-realtime-mini-2025-12-15\n",
      "o1\n",
      "o1-2024-12-17\n",
      "o1-pro\n",
      "o1-pro-2025-03-19\n",
      "o3\n",
      "o3-2025-04-16\n",
      "o3-mini\n",
      "o3-mini-2025-01-31\n",
      "o4-mini\n",
      "o4-mini-2025-04-16\n",
      "o4-mini-deep-research\n",
      "o4-mini-deep-research-2025-06-26\n",
      "omni-moderation-2024-09-26\n",
      "omni-moderation-latest\n",
      "sora-2\n",
      "sora-2-pro\n",
      "text-embedding-3-large\n",
      "text-embedding-3-small\n",
      "text-embedding-ada-002\n",
      "tts-1\n",
      "tts-1-1106\n",
      "tts-1-hd\n",
      "tts-1-hd-1106\n",
      "whisper-1\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "models = client.models.list()\n",
    "\n",
    "# Print nicely\n",
    "ids = sorted([m.id for m in models.data])\n",
    "print(f\"Total models visible: {len(ids)}\\n\")\n",
    "for mid in ids:\n",
    "    print(mid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ee44e5dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_ambivalent_sa_domain=True\n"
     ]
    }
   ],
   "source": [
    "test_prompt = DOMAIN_GATE_PROMPT.format(prompt_text=\"Original Post:\\nTitle: AIO is this SA?\\nBody: ...\")\n",
    "print(call_structured(MODEL, test_prompt, DomainGateOut))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "22553553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row: 5\n",
      "FULL prompt preview:\n",
      " Original Post:\n",
      "Author: AnteaterDue3967\n",
      "Title: Attracted to mainly Asian women and I felt like a creep for it.\n",
      "Body: Now to set the record straight I'm not that type of guy that's into super dainty, skinny short,docile, racist stereotype of Asian women. More into muscular/ forward or even alt type of girls of any race really  \n",
      "But to be honest I kind of have a thing for Asian women and part of me feels like it might be a race thing but not 100% sure if it's tha or because of the BS Hollywood fed  \n",
      "\n",
      "DOMAIN GATE: is_ambivalent_sa_domain=False | gate_used: full_body_fallback\n",
      "\n",
      "FINAL LABELS (forced):\n",
      "{\n",
      "  \"Information support\": \"NO\",\n",
      "  \"Emotional support\": \"NO\",\n",
      "  \"Esteem support\": \"NO\",\n",
      "  \"Network support\": \"NO\",\n",
      "  \"Tangible assistance\": \"NO\",\n",
      "  \"Seeking support\": \"NO\",\n",
      "  \"Group interactions\": \"NO\",\n",
      "  \"Not applicable\": \"YES\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "MODEL = \"openai/gpt-oss-120b:groq\"\n",
    "i = 5\n",
    "full_prompt_text = valid_df.iloc[i][\"prompt\"]\n",
    "\n",
    "print(\"Row:\", i)\n",
    "print(\"FULL prompt preview:\\n\", full_prompt_text[:500], \"\\n\")\n",
    "\n",
    "# Step 1: Domain gate (title-only ‚Üí fallback full body)\n",
    "dg_out, gate_used = domain_gate_title_then_fullbody(MODEL, full_prompt_text)\n",
    "print(\"DOMAIN GATE:\", dg_out, \"| gate_used:\", gate_used)\n",
    "\n",
    "if not dg_out.is_ambivalent_sa_domain:\n",
    "    pred = {lab: \"NO\" for lab in SUPPORT_ONLY_LABELS}\n",
    "    pred[\"Not applicable\"] = \"YES\"\n",
    "    print(\"\\nFINAL LABELS (forced):\")\n",
    "    print(json.dumps(pred, indent=2))\n",
    "else:\n",
    "    # Step 2\n",
    "    op_out = call_structured(MODEL, OP_LAST_COMMENT_PROMPT.format(prompt_text=full_prompt_text), LastCommentOut)\n",
    "    print(\"OP LAST COMMENT:\", op_out)\n",
    "\n",
    "    # Step 3\n",
    "    final_prompt = FINAL_MULTILABEL_PROMPT.format(\n",
    "        is_ambivalent_sa_domain=str(dg_out.is_ambivalent_sa_domain).lower(),\n",
    "        is_last_comment_by_op=str(op_out.is_last_comment_by_op).lower(),\n",
    "        last_comment_author=op_out.last_comment_author,\n",
    "        last_comment_content=op_out.last_comment_content,\n",
    "        support_definitions=SUPPORT_DEFINITIONS,\n",
    "        few_shot_examples=few_shot_examples,\n",
    "        prompt_text=full_prompt_text,\n",
    "    )\n",
    "    ml_out = call_structured(MODEL, final_prompt, MultiLabelOut)\n",
    "    pred = ml_out.to_label_dict()\n",
    "\n",
    "    print(\"\\nFINAL LABELS:\")\n",
    "    print(json.dumps(pred, indent=2))\n",
    "\n",
    "    yes_labels = [lab for lab in LABELS if pred.get(lab) == \"YES\"]\n",
    "    print(\"\\nYES labels:\", \", \".join(yes_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8b153bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Full validation (workers=1):   0%|          | 0/86 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[retry 1/6] ValueError: sleeping 0.75s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Full validation (workers=1):  13%|‚ñà‚ñé        | 11/86 [00:30<03:19,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[retry 1/6] ValueError: sleeping 0.75s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Full validation (workers=1):  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 46/86 [02:14<01:51,  2.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Empty/None content returned.\n",
      "finish_reason: length\n",
      "choice0: Choice(finish_reason='length', index=0, logprobs=None, message=ChatCompletionMessage(content='', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None, reasoning='We need to apply rules. is_ambivalent_sa_domain = true, so we proceed. is_last_comment_by_op = false (since author is Snoo_78896, not OP). So we go to \"Otherwise\" branch.\\n\\nWe must evaluate: Information support, Emotional support, Esteem support, Network support, Tangible assistance, Group interactions. Force: Seeking support = NO. Not applicable = YES only if all evaluated labels are NO.\\n\\nNow we need to label each based on the comment content.\\n\\nComment content: \"Im sorry that you feel the way you do. To be honest, you\\'re borh in the wrong here. 1. You put yourself in a vulnerable position to be taken advantage of. 2. He took advantage of you. You should be able to trust your boyfriend, and he should respect your decision not to want to have sex until YOU feel ready. Being drunk is no exception. Think about what the other comment is suggesting you do (press charges)? How will that go to the cops? I was with my boyfriend, we went to a party, we both got drunk and I know I lost my virginity but I dont remember.... ü§¶üèª\\u200d‚ôÄÔ∏è There is nothing you can do at this point. Whatever happened, already happened. But what you should do is get rid of that boyfriend of yours and heal. Take the time you need to forgive yourself and learn from the experience. I won\\'t drink 1 alcoholic beverage unless there is a trusted friend of mine with me. I, too, have made major mistakes in life while drunk that I regret. Please dont beat yourself up over this. Find a way to forgive yourself and hit a mental reset. It\\'s never too late to start over. Be easy on yourself. ‚ú®Ô∏è\\U0001fa77\"\\n\\nWe need to see if it contains:\\n\\nInformation support: giving advice, facts, resources, explanations, or opinionated judgments used to inform/guide. This comment includes advice: \"You should be able to trust your boyfriend... Being drunk is no exception.\" Also \"There is nothing you can do at this point.\" \"What you should do is get rid of that boyfriend...\". That\\'s advice. So Information support = YES.\\n\\nEmotional support: expresses care, empathy, comforting, apologizing, \"I\\'m sorry that you feel the way you do.\" Also \"Please don\\'t beat yourself up...\". That\\'s emotional support. So Emotional support = YES.\\n\\nEsteem support: building user up, complimenting, validating feelings as reasonable/normal. The comment says \"You put yourself in a vulnerable position\" (blame) and \"You should be able to trust your boyfriend\". Not really building up. It does say \"Find a way to forgive yourself... Be easy on yourself.\" That\\'s more self-compassion suggestion, maybe some validation. But does it validate feelings? It says \"I\\'m sorry you feel the way you do.\" That\\'s acknowledging feelings, but esteem support is more about complimenting or validating feelings as reasonable. Could be considered validation of feelings? Might be borderline. However, the comment also says \"you\\'re both in the wrong here\" and \"You put yourself in a vulnerable position\". That\\'s more blame, not esteem. So likely Esteem support = NO.\\n\\nNetwork support: encouraging to reach out to external help systems. The comment suggests \"get rid of that boyfriend\" and \"heal\", \"take time\". Not specifically encouraging therapy, friends, police. It mentions \"How will that go to the cops?\" but that\\'s a question, not suggestion to go. So Network support = NO.\\n\\nTangible assistance: offering personal help directly. The comment does not say \"I can help you\" or \"I\\'m here\". So NO.\\n\\nGroup interactions: any reply that primarily participates socially, sharing own experience, gratitude, etc. This comment includes personal anecdote: \"I was with my boyfriend, we went to a party, we both got drunk and I know I lost my virginity but I dont remember....\". That\\'s sharing own experience. That qualifies as group interaction (sharing own story). Also includes advice. Group interactions can co-occur. So Group interactions = YES.\\n\\nSeeking support: forced NO.\\n\\nNow Not applicable = YES only if all evaluated labels are NO. Since we have some YES, Not applicable = NO.\\n\\nThus final JSON:\\n\\nInformation support: YES\\nEmotional support: YES\\nEsteem support: NO\\nNetwork support: NO\\nTangible assistance:'))\n",
      "[retry 1/6] ValueError: sleeping 0.75s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Full validation (workers=1):  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 57/86 [02:51<01:25,  2.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG: Empty/None content returned.\n",
      "finish_reason: length\n",
      "choice0: Choice(finish_reason='length', index=0, logprobs=None, message=ChatCompletionMessage(content='', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None, reasoning='We need to follow steps:\\n\\n1) Extract OP author from Original Post: Author: DaddyBren42\\n\\n2) Choose comment with highest depth in conversation history. Depth values: 0,1,2,3,4,5. Highest is depth 5.\\n\\n3) Extract that last comment\\'s Author, Depth, Content. Depth 5 comment: Author: ParentPostLacksWang, Content: (the long paragraph). Need to capture content exactly as given.\\n\\n4) Compare last comment author with OP. OP is DaddyBren42, last comment author is ParentPostLacksWang, so not same => false.\\n\\nReturn JSON with fields.\\n\\nWe must ensure JSON formatting, strings escaped properly. Provide content as a string; need to preserve line breaks? Usually we can keep as single line with spaces. We\\'ll include the content exactly as in the comment, preserving line breaks maybe as \\\\n. But simpler: keep as one string with spaces.\\n\\nLet\\'s copy content:\\n\\n\"Not every experience is like yours.  Not everybody is affected with PTSD by rape.  Not every rape is violent, or involves physical restraint.  It‚Äôs not great to say that a rape wasn‚Äôt ‚Äúbad enough‚Äù to be considered a ‚Äúreal rape‚Äù.\\n\\nWas OP raped?  Certainly a 16 year old grooming and sexually touching a 12 year old is a form of molestation, and society is pretty clear that molesting a child (which OP was) is considered rape.  Is it at the limit of what society defines as rape?  Yes, probably.\\n\\nWhat happened to us is awful, and you have my deepest empathy - but I also have empathy for OP, because this kind of molestation can have considerable psychological impacts later in life too.  It can reshape people‚Äôs relationship with sex and sexuality, certainly.  Is it as toxic, painful, damaging?  No, but it isn‚Äôt a competition.\\n\\nImagine some alternative universe where you were such an incredibly psychopathic hardass that your experience didn‚Äôt shake you, that you were able to look back on it and just say ‚Äúwhatever‚Äù, no PTSD, no flashbacks, no effect on your life.  That doesn‚Äôt make what happened better.  Now imagine yourself far more sensitive than you are now, but what happened was equally far less bad.  You would feel the same way about it as you do now, but might have to listen to someone tell you it wasn‚Äôt a real rape.\\n\\nDifferent people have different thresholds for psychological effects, that‚Äôs diversity and that‚Äôs okay.\"\\n\\nWe need to ensure proper escaping of quotes inside string. Use double quotes for JSON, so internal double quotes need escaping. There are many double quotes like ‚Äúbad enough‚Äù. Those are curly quotes, not ASCII double quotes, so they are fine. There are also straight double quotes around \"whatever\". That needs escaping. Also there are quotes around ‚Äúreal rape‚Äù. Those are curly. So only straight double quotes need escaping. The phrase: say ‚Äúwhatever‚Äù, no PTSD... Actually it\\'s curly quotes? It uses ‚Äúwhatever‚Äù. That\\'s curly. So no need. The earlier part: ‚Äúbad enough‚Äù also curly. So fine.\\n\\nThus JSON:\\n\\n{\\n  \"op_author\": \"DaddyBren42\",\\n  \"last_comment_depth\": 5,\\n  \"last_comment_author\": \"ParentPostLacksWang\",\\n  \"last_comment_content\": \"Not every experience is like yours.  Not everybody is affected with PTSD by rape.  Not every rape is violent, or involves physical restraint.  It‚Äôs not great to say that a rape wasn‚Äôt ‚Äúbad enough‚Äù to be considered a ‚Äúreal rape‚Äù.\\\\n\\\\nWas OP raped?  Certainly a 16 year old grooming and sexually touching a 12 year old is a form of molestation, and society is pretty clear that molesting a child (which OP was) is considered rape.  Is it at the limit of what society defines as rape?  Yes, probably.\\\\n\\\\nWhat happened to us is awful, and you have my deepest empathy - but I also have empathy for OP, because this kind of molestation can have considerable psychological impacts later in life too.  It can reshape people‚Äôs relationship with sex and sexuality, certainly.  Is it as toxic, painful, damaging?  No, but it isn‚Äôt a competition.\\\\n\\\\nImagine some alternative universe where you were such an incredibly psychopathic hardass that'))\n",
      "[retry 1/6] ValueError: sleeping 0.75s\n",
      "DEBUG: Empty/None content returned.\n",
      "finish_reason: length\n",
      "choice0: Choice(finish_reason='length', index=0, logprobs=None, message=ChatCompletionMessage(content='', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None, reasoning='We need to follow steps.\\n\\n1) Extract OP author from Original Post: Author: DaddyBren42.\\n\\n2) Choose comment with highest depth in conversation history. Depth values: 0,1,2,3,4,5. Highest is depth 5.\\n\\n3) Extract that last comment\\'s Author, Depth, Content. Depth 5 comment: Author: ParentPostLacksWang. Content: (the long paragraph). Need to capture full content.\\n\\n4) Compare last comment author with OP. OP is DaddyBren42, last comment author is ParentPostLacksWang, so not same => false.\\n\\nReturn JSON with fields.\\n\\nWe need to ensure proper JSON formatting, strings escaped if needed. Content includes quotes and apostrophes. Need to escape double quotes inside JSON string. The content includes double quotes? Let\\'s check: The content includes: \"Was OP raped?  Certainly a 16 year old grooming and ...\". It has double quotes around \"Was OP raped?\" Actually it\\'s a question with double quotes? The text: \"Was OP raped?  Certainly a 16 year old grooming and sexually touching a 12 year old is a form of molestation, and society is pretty clear that molesting a child (which OP was) is considered rape.  Is it at the limit of what society defines as rape?  Yes, probably.\"\\n\\nThere are double quotes around the whole content? In the provided text, it\\'s not wrapped in quotes, it\\'s just plain text. It includes apostrophes and maybe double quotes? Let\\'s scan: \"Was OP raped?  Certainly a 16 year old grooming and sexually touching a 12 year old is a form of molestation, and society is pretty clear that molesting a child (which OP was) is considered rape.  Is it at the limit of what society defines as rape?  Yes, probably.\"\\n\\nThere are no double quotes inside. There\\'s an apostrophe in \"it\\'s\"? Actually not. There\\'s \"it\\'s\" maybe? Let\\'s see: \"Is it at the limit of what society defines as rape?  Yes, probably.\" No apostrophe. There\\'s \"doesn\\'t\" earlier? Not in this comment. There\\'s \"doesn\\'t\"? Not. So we can include as is.\\n\\nMake sure to preserve line breaks? JSON string can have \\\\n. We\\'ll just keep as single line with spaces.\\n\\nLet\\'s copy content exactly as in comment depth 5:\\n\\n\"Not every experience is like yours.  Not everybody is affected with PTSD by rape.  Not every rape is violent, or involves physical restraint.  It‚Äôs not great to say that a rape wasn‚Äôt ‚Äúbad enough‚Äù to be considered a ‚Äúreal rape‚Äù.\\n\\nWas OP raped?  Certainly a 16 year old grooming and sexually touching a 12 year old is a form of molestation, and society is pretty clear that molesting a child (which OP was) is considered rape.  Is it at the limit of what society defines as rape?  Yes, probably.\\n\\nWhat happened to us is awful, and you have my deepest empathy - but I also have empathy for OP, because this kind of molestation can have considerable psychological impacts later in life too.  It can reshape people‚Äôs relationship with sex and sexuality, certainly.  Is it as toxic, painful, damaging?  No, but it isn‚Äôt a competition.\\n\\nImagine some alternative universe where you were such an incredibly psychopathic hardass that your experience didn‚Äôt shake you, that you were able to look back on it and just say ‚Äúwhatever‚Äù, no PTSD, no flashbacks, no effect on your life.  That doesn‚Äôt make what happened better.  Now imagine yourself far more sensitive than you are now, but what happened was equally far less bad.  You would feel the same way about it as you do now, but might have to listen to someone tell you it wasn‚Äôt a real rape.\\n\\nDifferent people have different thresholds for psychological effects, that‚Äôs diversity and that‚Äôs okay.\"\\n\\nThere are curly quotes ‚Äú ‚Äù and apostrophes ‚Äô. Those are Unicode characters, fine.\\n\\nWe need to escape newlines as \\\\n. Provide JSON.\\n\\nLet\\'s construct JSON:\\n\\n{\\n  \"op_author\": \"DaddyBren42\",\\n  \"last_comment_depth\": 5,\\n  \"last_comment_author\": \"ParentPostLacksWang\",\\n  \"last_comment_content\": \"Not every experience is like yours.  Not everybody is affected'))\n",
      "[retry 2/6] ValueError: sleeping 1.12s\n",
      "DEBUG: Empty/None content returned.\n",
      "finish_reason: length\n",
      "choice0: Choice(finish_reason='length', index=0, logprobs=None, message=ChatCompletionMessage(content='', refusal=None, role='assistant', annotations=None, audio=None, function_call=None, tool_calls=None, reasoning='We need to follow steps:\\n\\n1) Extract OP author from Original Post: Author: DaddyBren42\\n\\n2) Choose comment with highest depth in conversation history. Depth values: 0,1,2,3,4,5. Highest is depth 5.\\n\\n3) Extract that last comment\\'s Author, Depth, Content.\\n\\nDepth 5 comment:\\nAuthor: ParentPostLacksWang\\nContent: (the long paragraph). Need to capture exactly as given.\\n\\n4) Compare last comment author with OP. OP is DaddyBren42, last comment author is ParentPostLacksWang, so false.\\n\\nReturn JSON with fields.\\n\\nMake sure JSON formatting correct, strings escaped if needed. Content includes quotes and apostrophes. Need to escape double quotes inside string. The content includes double quotes? Let\\'s check: The content includes: \"Was OP raped?  Certainly a 16 year old grooming and sexually touching a 12 year old is a form of molestation, and society is pretty clear that molesting a child (which OP was) is considered rape.  Is it at the limit of what society defines as rape?  Yes, probably.\\n\\nWhat happened to us is awful, and you have my deepest empathy - but I also have empathy for OP, because this kind of molestation can have considerable psychological impacts later in life too.  It can reshape people‚Äôs relationship with sex and sexuality, certainly.  Is it as toxic, painful, damaging?  No, but it isn‚Äôt a competition.\\n\\nImagine some alternative universe where you were such an incredibly psychopathic hardass that your experience didn‚Äôt shake you, that you were able to look back on it and just say ‚Äúwhatever‚Äù, no PTSD, no flashbacks, no effect on your life.  That doesn‚Äôt make what happened better.  Now imagine yourself far more sensitive than you are now, but what happened was equally far less bad.  You would feel the same way about it as you do now, but might have to listen to someone tell you it wasn‚Äôt a real rape.\\n\\nDifferent people have different thresholds for psychological effects, that‚Äôs diversity and that‚Äôs okay.\"\\n\\nThere are curly quotes ‚Äú ‚Äù and apostrophes ‚Äô. Those are fine. Need to escape double quotes (the JSON string uses double quotes). The content includes double quotes around ‚Äúwhatever‚Äù. Those are curly quotes, not ASCII double quotes, so they are not the same as \". So no need to escape. Also there are apostrophes ‚Äô which are fine.\\n\\nThus JSON:\\n\\n{\\n \"op_author\": \"DaddyBren42\",\\n \"last_comment_depth\": 5,\\n \"last_comment_author\": \"ParentPostLacksWang\",\\n \"last_comment_content\": \"Not every experience is like yours.  Not everybody is affected with PTSD by rape.  Not every rape is violent, or involves physical restraint.  It‚Äôs not great to say that a rape wasn‚Äôt ‚Äúbad enough‚Äù to be considered a ‚Äúreal rape‚Äù.\\\\n\\\\nWas OP raped?  Certainly a 16 year old grooming and sexually touching a 12 year old is a form of molestation, and society is pretty clear that molesting a child (which OP was) is considered rape.  Is it at the limit of what society defines as rape?  Yes, probably.\\\\n\\\\nWhat happened to us is awful, and you have my deepest empathy - but I also have empathy for OP, because this kind of molestation can have considerable psychological impacts later in life too.  It can reshape people‚Äôs relationship with sex and sexuality, certainly.  Is it as toxic, painful, damaging?  No, but it isn‚Äôt a competition.\\\\n\\\\nImagine some alternative universe where you were such an incredibly psychopathic hardass that your experience didn‚Äôt shake you, that you were able to look back on it and just say ‚Äúwhatever‚Äù, no PTSD, no flashbacks, no effect on your life.  That doesn‚Äôt make what happened better.  Now imagine yourself far more sensitive than you are now, but what happened was equally far less bad.  You would feel the same way about it as you do now, but might have to listen to someone tell you it wasn‚Äôt a real rape.\\\\n\\\\nDifferent people have different thresholds for psychological effects, that‚Äôs diversity and that‚Äôs okay.\",\\n \"is_last_comment_by_op\": false\\n}\\n\\nMake sure newline representation is okay. Could keep as single line but'))\n",
      "[retry 3/6] ValueError: sleeping 1.69s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Full validation (workers=1): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 86/86 [04:14<00:00,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: valid_with_predictions_goss_v86.csv\n",
      "Left existing 'Tags' untouched. Errors are in 'llm_error'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures as cf\n",
    "from tqdm import tqdm\n",
    "\n",
    "MODEL = \"openai/gpt-oss-120b:groq\"\n",
    "MAX_WORKERS = 1   # start low; increase only if you stop seeing 429s\n",
    "\n",
    "ERROR_COL = \"llm_error\"\n",
    "YES_LABEL_COL = \"predicted_labels_yes\"\n",
    "GATE_USED_COL = \"gate_used\"\n",
    "\n",
    "# Ensure OUR output columns exist (do NOT touch Tags)\n",
    "base_cols = [\n",
    "    \"is_ambivalent_sa_domain\",\n",
    "    \"op_author\",\n",
    "    \"last_comment_depth\",\n",
    "    \"last_comment_author\",\n",
    "    \"is_last_comment_by_op\",\n",
    "    ERROR_COL,\n",
    "    YES_LABEL_COL,\n",
    "    GATE_USED_COL,\n",
    "]\n",
    "for col in base_cols:\n",
    "    if col not in valid_df.columns:\n",
    "        valid_df[col] = None\n",
    "\n",
    "for lab in LABELS:\n",
    "    if lab not in valid_df.columns:\n",
    "        valid_df[lab] = None\n",
    "\n",
    "def run_one(full_prompt_text: str):\n",
    "    # Step 1: title-only ‚Üí fallback full body\n",
    "    dg_out, gate_used = domain_gate_title_then_fullbody(MODEL, full_prompt_text)\n",
    "\n",
    "    if not dg_out.is_ambivalent_sa_domain:\n",
    "        pred = {lab: \"NO\" for lab in SUPPORT_ONLY_LABELS}\n",
    "        pred[\"Not applicable\"] = \"YES\"\n",
    "        yes_labels = [lab for lab, v in pred.items() if v == \"YES\"]\n",
    "        return {\n",
    "            \"gate_used\": gate_used,\n",
    "            \"is_ambivalent_sa_domain\": False,\n",
    "            \"op_author\": None,\n",
    "            \"last_comment_depth\": None,\n",
    "            \"last_comment_author\": None,\n",
    "            \"is_last_comment_by_op\": None,\n",
    "            \"pred\": pred,\n",
    "            \"predicted_labels_yes\": \", \".join(yes_labels),\n",
    "            \"error\": None,\n",
    "        }\n",
    "\n",
    "    # Step 2\n",
    "    op_out = call_structured(MODEL, OP_LAST_COMMENT_PROMPT.format(prompt_text=full_prompt_text), LastCommentOut)\n",
    "\n",
    "    # Step 3\n",
    "    final_prompt = FINAL_MULTILABEL_PROMPT.format(\n",
    "        is_ambivalent_sa_domain=str(dg_out.is_ambivalent_sa_domain).lower(),\n",
    "        is_last_comment_by_op=str(op_out.is_last_comment_by_op).lower(),\n",
    "        last_comment_author=op_out.last_comment_author,\n",
    "        last_comment_content=op_out.last_comment_content,\n",
    "        support_definitions=SUPPORT_DEFINITIONS,\n",
    "        few_shot_examples=few_shot_examples,\n",
    "        prompt_text=full_prompt_text,\n",
    "    )\n",
    "    ml_out = call_structured(MODEL, final_prompt, MultiLabelOut)\n",
    "    pred = ml_out.to_label_dict()\n",
    "    yes_labels = [lab for lab, v in pred.items() if v == \"YES\"]\n",
    "\n",
    "    return {\n",
    "        \"gate_used\": gate_used,\n",
    "        \"is_ambivalent_sa_domain\": True,\n",
    "        \"op_author\": op_out.op_author,\n",
    "        \"last_comment_depth\": op_out.last_comment_depth,\n",
    "        \"last_comment_author\": op_out.last_comment_author,\n",
    "        \"is_last_comment_by_op\": op_out.is_last_comment_by_op,\n",
    "        \"pred\": pred,\n",
    "        \"predicted_labels_yes\": \", \".join(yes_labels),\n",
    "        \"error\": None,\n",
    "    }\n",
    "\n",
    "# Parallel run\n",
    "futures = {}\n",
    "with cf.ThreadPoolExecutor(max_workers=MAX_WORKERS) as ex:\n",
    "    for i, row in valid_df.iterrows():\n",
    "        # Optional resume: skip rows already done successfully\n",
    "        if pd.notna(row.get(YES_LABEL_COL)) and str(row.get(ERROR_COL, \"\")).strip() in {\"\", \"nan\", \"None\"}:\n",
    "            continue\n",
    "        futures[ex.submit(run_one, row[\"prompt\"])] = i\n",
    "\n",
    "    for fut in tqdm(cf.as_completed(futures), total=len(futures), desc=f\"Full validation (workers={MAX_WORKERS})\"):\n",
    "        i = futures[fut]\n",
    "        try:\n",
    "            out = fut.result()\n",
    "\n",
    "            valid_df.at[i, GATE_USED_COL] = out[\"gate_used\"]\n",
    "            valid_df.at[i, \"is_ambivalent_sa_domain\"] = out[\"is_ambivalent_sa_domain\"]\n",
    "            valid_df.at[i, \"op_author\"] = out[\"op_author\"]\n",
    "            valid_df.at[i, \"last_comment_depth\"] = out[\"last_comment_depth\"]\n",
    "            valid_df.at[i, \"last_comment_author\"] = out[\"last_comment_author\"]\n",
    "            valid_df.at[i, \"is_last_comment_by_op\"] = out[\"is_last_comment_by_op\"]\n",
    "\n",
    "            for lab, val in out[\"pred\"].items():\n",
    "                valid_df.at[i, lab] = val\n",
    "\n",
    "            valid_df.at[i, YES_LABEL_COL] = out[\"predicted_labels_yes\"]\n",
    "            valid_df.at[i, ERROR_COL] = out[\"error\"]\n",
    "\n",
    "        except Exception as e:\n",
    "            valid_df.at[i, ERROR_COL] = str(e)\n",
    "\n",
    "# Save once\n",
    "OUT_PATH = \"valid_with_predictions_goss_v86.csv\"\n",
    "valid_df.to_csv(OUT_PATH, index=False)\n",
    "print(\"Saved:\", OUT_PATH)\n",
    "print(f\"Left existing 'Tags' untouched. Errors are in '{ERROR_COL}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "099c932e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reset done. Now rerun full validation with o4-mini.\n"
     ]
    }
   ],
   "source": [
    "cols_to_reset = [\n",
    "    \"is_ambivalent_sa_domain\",\"op_author\",\"last_comment_depth\",\"last_comment_author\",\"is_last_comment_by_op\",\n",
    "    \"gate_used\",\"llm_error\",\"predicted_labels_yes\",\n",
    "    \"Information support\",\"Emotional support\",\"Esteem support\",\"Network support\",\n",
    "    \"Tangible assistance\",\"Seeking support\",\"Group interactions\",\"Not applicable\",\n",
    "]\n",
    "for c in cols_to_reset:\n",
    "    if c in valid_df.columns:\n",
    "        valid_df[c] = None\n",
    "\n",
    "print(\"Reset done. Now rerun full validation with o4-mini.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6201d315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: valid_with_predictions_goss_v86.csv\n",
      "Rows: 86\n",
      "Columns: ['post_id', 'parent_id', 'subreddit', 'comment_id', 'parent_fullname', 'depth', 'comment_author', 'comment_body', 'comment_score', 'created_utc', 'permalink', 'is_post_author', 'title', 'author', 'body', 'prompt', 'Tags', 'is_ambivalent_sa_domain', 'op_author', 'last_comment_depth', 'last_comment_author', 'is_last_comment_by_op', 'llm_error', 'predicted_labels_yes', 'gate_used', 'Information support', 'Emotional support', 'Esteem support', 'Network support', 'Tangible assistance', 'Seeking support', 'Group interactions', 'Not applicable']\n",
      "\n",
      "Empty ground-truth rows: 0\n",
      "Empty prediction rows: 0\n",
      "\n",
      "Evaluating on labels (excluded: Not applicable, Seeking support):\n",
      "['Information support' 'Emotional support' 'Esteem support'\n",
      " 'Network support' 'Tangible assistance' 'Group interactions']\n",
      "\n",
      "Overall Precision \\& Recall \\& F1 (EXCLUDING Not applicable + Seeking support)\n",
      "micro_precision: 0.9292\n",
      "micro_recall: 0.8015\n",
      "micro_f1: 0.8607\n",
      "macro_precision: 0.9362\n",
      "macro_recall: 0.7989\n",
      "macro_f1: 0.8554\n",
      "samples_precision: 0.6899\n",
      "samples_recall: 0.6469\n",
      "samples_f1: 0.6562\n",
      "\n",
      "Per-label metrics (excluded labels removed):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>support_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tangible assistance</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Information support</td>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.932039</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Emotional support</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Network support</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Group interactions</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Esteem support</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 label  precision    recall        f1  support_true\n",
       "4  Tangible assistance   1.000000  1.000000  1.000000             2\n",
       "0  Information support   0.979592  0.888889  0.932039            54\n",
       "1    Emotional support   0.896552  0.962963  0.928571            27\n",
       "3      Network support   1.000000  0.750000  0.857143             4\n",
       "5   Group interactions   0.928571  0.650000  0.764706            20\n",
       "2       Esteem support   0.812500  0.541667  0.650000            24"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report (excluded labels removed):\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "Information support       0.98      0.89      0.93        54\n",
      "  Emotional support       0.90      0.96      0.93        27\n",
      "     Esteem support       0.81      0.54      0.65        24\n",
      "    Network support       1.00      0.75      0.86         4\n",
      "Tangible assistance       1.00      1.00      1.00         2\n",
      " Group interactions       0.93      0.65      0.76        20\n",
      "\n",
      "          micro avg       0.93      0.80      0.86       131\n",
      "          macro avg       0.94      0.80      0.86       131\n",
      "       weighted avg       0.93      0.80      0.85       131\n",
      "        samples avg       0.69      0.65      0.66       131\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import (\n",
    "    precision_score, recall_score, f1_score,\n",
    "    classification_report, precision_recall_fscore_support\n",
    ")\n",
    "\n",
    "# ====== 1) LOAD YOUR FILE ======\n",
    "IN_PATH = \"valid_with_predictions_goss_v86.csv\"\n",
    "df = pd.read_csv(IN_PATH)\n",
    "\n",
    "print(\"Loaded:\", IN_PATH)\n",
    "print(\"Rows:\", len(df))\n",
    "print(\"Columns:\", list(df.columns))\n",
    "\n",
    "# ====== 2) LABEL SET ======\n",
    "ALL_LABELS = [\n",
    "    \"Information support\",\n",
    "    \"Emotional support\",\n",
    "    \"Esteem support\",\n",
    "    \"Network support\",\n",
    "    \"Tangible assistance\",\n",
    "    \"Seeking support\",\n",
    "    \"Group interactions\",\n",
    "    \"Not applicable\",\n",
    "]\n",
    "\n",
    "EXCLUDE_LABELS = {\"Not applicable\", \"Seeking support\"}\n",
    "EVAL_LABELS = [lab for lab in ALL_LABELS if lab not in EXCLUDE_LABELS]\n",
    "\n",
    "# map for case/spacing normalization\n",
    "_norm_map = {lab.lower().strip(): lab for lab in ALL_LABELS}\n",
    "\n",
    "def normalize_label(t: str):\n",
    "    t2 = str(t).strip()\n",
    "    if not t2:\n",
    "        return None\n",
    "    key = t2.lower().strip()\n",
    "    return _norm_map.get(key, None)  # canonical label or None if unknown\n",
    "\n",
    "# ====== 3) PARSE TAG STRINGS ======\n",
    "def parse_labels(x):\n",
    "    if x is None or (isinstance(x, float) and np.isnan(x)):\n",
    "        return []\n",
    "    s = str(x).strip()\n",
    "    if s == \"\" or s.lower() in {\"nan\", \"none\"}:\n",
    "        return []\n",
    "\n",
    "    labels = []\n",
    "\n",
    "    # Try JSON list\n",
    "    if s.startswith(\"[\") and s.endswith(\"]\"):\n",
    "        try:\n",
    "            obj = json.loads(s)\n",
    "            labels = [str(t).strip() for t in obj]\n",
    "        except Exception:\n",
    "            try:\n",
    "                obj = json.loads(re.sub(r\"'\", '\"', s))\n",
    "                labels = [str(t).strip() for t in obj]\n",
    "            except Exception:\n",
    "                labels = []\n",
    "\n",
    "    # Fallback split\n",
    "    if not labels:\n",
    "        parts = re.split(r\"[,\\n;|]+\", s)\n",
    "        labels = []\n",
    "        for t in parts:\n",
    "            t = re.sub(r\"^tags?\\s*:\\s*\", \"\", t.strip(), flags=re.IGNORECASE)\n",
    "            if t:\n",
    "                labels.append(t)\n",
    "\n",
    "    # Normalize + keep only known labels\n",
    "    out = []\n",
    "    for t in labels:\n",
    "        canon = normalize_label(t)\n",
    "        if canon is not None:\n",
    "            out.append(canon)\n",
    "\n",
    "    # de-dup while preserving order\n",
    "    seen = set()\n",
    "    out2 = []\n",
    "    for t in out:\n",
    "        if t not in seen:\n",
    "            seen.add(t)\n",
    "            out2.append(t)\n",
    "    return out2\n",
    "\n",
    "# ====== 4) BUILD y_true / y_pred ======\n",
    "assert \"Tags\" in df.columns, \"Missing ground-truth column: Tags\"\n",
    "assert \"predicted_labels_yes\" in df.columns, \"Missing prediction column: predicted_labels_yes\"\n",
    "\n",
    "y_true_list_all = df[\"Tags\"].apply(parse_labels).tolist()\n",
    "y_pred_list_all = df[\"predicted_labels_yes\"].apply(parse_labels).tolist()\n",
    "\n",
    "print(\"\\nEmpty ground-truth rows:\", sum(len(x) == 0 for x in y_true_list_all))\n",
    "print(\"Empty prediction rows:\", sum(len(x) == 0 for x in y_pred_list_all))\n",
    "\n",
    "# --- Filter OUT excluded labels at the list level (optional but keeps things clean)\n",
    "def drop_excluded(labels):\n",
    "    return [t for t in labels if t not in EXCLUDE_LABELS]\n",
    "\n",
    "y_true_list = [drop_excluded(x) for x in y_true_list_all]\n",
    "y_pred_list = [drop_excluded(x) for x in y_pred_list_all]\n",
    "\n",
    "# Binarize ONLY over evaluation labels\n",
    "mlb = MultiLabelBinarizer(classes=EVAL_LABELS)\n",
    "Y_true = mlb.fit_transform(y_true_list)\n",
    "Y_pred = mlb.transform(y_pred_list)\n",
    "\n",
    "print(\"\\nEvaluating on labels (excluded: Not applicable, Seeking support):\")\n",
    "print(mlb.classes_)\n",
    "\n",
    "# ====== 5) OVERALL METRICS ======\n",
    "scores = {\n",
    "    \"micro_precision\": precision_score(Y_true, Y_pred, average=\"micro\", zero_division=0),\n",
    "    \"micro_recall\":    recall_score(Y_true, Y_pred, average=\"micro\", zero_division=0),\n",
    "    \"micro_f1\":        f1_score(Y_true, Y_pred, average=\"micro\", zero_division=0),\n",
    "\n",
    "    \"macro_precision\": precision_score(Y_true, Y_pred, average=\"macro\", zero_division=0),\n",
    "    \"macro_recall\":    recall_score(Y_true, Y_pred, average=\"macro\", zero_division=0),\n",
    "    \"macro_f1\":        f1_score(Y_true, Y_pred, average=\"macro\", zero_division=0),\n",
    "\n",
    "    \"samples_precision\": precision_score(Y_true, Y_pred, average=\"samples\", zero_division=0),\n",
    "    \"samples_recall\":    recall_score(Y_true, Y_pred, average=\"samples\", zero_division=0),\n",
    "    \"samples_f1\":        f1_score(Y_true, Y_pred, average=\"samples\", zero_division=0),\n",
    "}\n",
    "\n",
    "print(\"\\nOverall Precision \\\\& Recall \\\\& F1 (EXCLUDING Not applicable + Seeking support)\")\n",
    "for k, v in scores.items():\n",
    "    print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "# ====== 6) PER-LABEL METRICS ======\n",
    "p, r, f1, support = precision_recall_fscore_support(\n",
    "    Y_true, Y_pred, average=None, zero_division=0\n",
    ")\n",
    "\n",
    "per_label_df = pd.DataFrame({\n",
    "    \"label\": mlb.classes_,\n",
    "    \"precision\": p,\n",
    "    \"recall\": r,\n",
    "    \"f1\": f1,\n",
    "    \"support_true\": support\n",
    "}).sort_values(\"f1\", ascending=False)\n",
    "\n",
    "print(\"\\nPer-label metrics (excluded labels removed):\")\n",
    "display(per_label_df)\n",
    "\n",
    "print(\"\\nClassification report (excluded labels removed):\")\n",
    "print(classification_report(Y_true, Y_pred, target_names=mlb.classes_, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "89422069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: test_with_predictions_goss_t44.csv\n",
      "Rows: 44\n",
      "Columns: ['post_id', 'parent_id', 'subreddit', 'comment_id', 'parent_fullname', 'depth', 'comment_author', 'comment_body', 'comment_score', 'created_utc', 'permalink', 'is_post_author', 'title', 'author', 'body', 'prompt', 'Tags', 'is_ambivalent_sa_domain', 'op_author', 'last_comment_depth', 'last_comment_author', 'is_last_comment_by_op', 'llm_error', 'predicted_labels_yes', 'gate_used', 'Information support', 'Emotional support', 'Esteem support', 'Network support', 'Tangible assistance', 'Seeking support', 'Group interactions', 'Not applicable']\n",
      "\n",
      "Empty ground-truth rows: 0\n",
      "Empty prediction rows: 0\n",
      "\n",
      "Evaluating on labels (excluded: Not applicable, Seeking support):\n",
      "['Information support' 'Emotional support' 'Esteem support'\n",
      " 'Network support' 'Tangible assistance' 'Group interactions']\n",
      "\n",
      "Overall Precision \\& Recall \\& F1 (EXCLUDING Not applicable + Seeking support)\n",
      "micro_precision: 0.9400\n",
      "micro_recall: 0.7966\n",
      "micro_f1: 0.8624\n",
      "macro_precision: 0.7926\n",
      "macro_recall: 0.6833\n",
      "macro_f1: 0.7210\n",
      "samples_precision: 0.5909\n",
      "samples_recall: 0.5682\n",
      "samples_f1: 0.5746\n",
      "\n",
      "Per-label metrics (excluded labels removed):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>support_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Network support</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Emotional support</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Information support</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Group interactions</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Esteem support</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tangible assistance</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 label  precision  recall        f1  support_true\n",
       "3      Network support   1.000000     1.0  1.000000             1\n",
       "1    Emotional support   0.866667     1.0  0.928571            13\n",
       "0  Information support   1.000000     0.8  0.888889            25\n",
       "5   Group interactions   0.888889     0.8  0.842105            10\n",
       "2       Esteem support   1.000000     0.5  0.666667            10\n",
       "4  Tangible assistance   0.000000     0.0  0.000000             0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report (excluded labels removed):\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "Information support       1.00      0.80      0.89        25\n",
      "  Emotional support       0.87      1.00      0.93        13\n",
      "     Esteem support       1.00      0.50      0.67        10\n",
      "    Network support       1.00      1.00      1.00         1\n",
      "Tangible assistance       0.00      0.00      0.00         0\n",
      " Group interactions       0.89      0.80      0.84        10\n",
      "\n",
      "          micro avg       0.94      0.80      0.86        59\n",
      "          macro avg       0.79      0.68      0.72        59\n",
      "       weighted avg       0.95      0.80      0.85        59\n",
      "        samples avg       0.59      0.57      0.57        59\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import (\n",
    "    precision_score, recall_score, f1_score,\n",
    "    classification_report, precision_recall_fscore_support\n",
    ")\n",
    "\n",
    "# ====== 1) LOAD YOUR FILE ======\n",
    "IN_PATH = \"test_with_predictions_goss_t44.csv\"\n",
    "df = pd.read_csv(IN_PATH)\n",
    "\n",
    "print(\"Loaded:\", IN_PATH)\n",
    "print(\"Rows:\", len(df))\n",
    "print(\"Columns:\", list(df.columns))\n",
    "\n",
    "# ====== 2) LABEL SET ======\n",
    "ALL_LABELS = [\n",
    "    \"Information support\",\n",
    "    \"Emotional support\",\n",
    "    \"Esteem support\",\n",
    "    \"Network support\",\n",
    "    \"Tangible assistance\",\n",
    "    \"Seeking support\",\n",
    "    \"Group interactions\",\n",
    "    \"Not applicable\",\n",
    "]\n",
    "\n",
    "EXCLUDE_LABELS = {\"Not applicable\", \"Seeking support\"}\n",
    "EVAL_LABELS = [lab for lab in ALL_LABELS if lab not in EXCLUDE_LABELS]\n",
    "\n",
    "# map for case/spacing normalization\n",
    "_norm_map = {lab.lower().strip(): lab for lab in ALL_LABELS}\n",
    "\n",
    "def normalize_label(t: str):\n",
    "    t2 = str(t).strip()\n",
    "    if not t2:\n",
    "        return None\n",
    "    key = t2.lower().strip()\n",
    "    return _norm_map.get(key, None)  # canonical label or None if unknown\n",
    "\n",
    "# ====== 3) PARSE TAG STRINGS ======\n",
    "def parse_labels(x):\n",
    "    if x is None or (isinstance(x, float) and np.isnan(x)):\n",
    "        return []\n",
    "    s = str(x).strip()\n",
    "    if s == \"\" or s.lower() in {\"nan\", \"none\"}:\n",
    "        return []\n",
    "\n",
    "    labels = []\n",
    "\n",
    "    # Try JSON list\n",
    "    if s.startswith(\"[\") and s.endswith(\"]\"):\n",
    "        try:\n",
    "            obj = json.loads(s)\n",
    "            labels = [str(t).strip() for t in obj]\n",
    "        except Exception:\n",
    "            try:\n",
    "                obj = json.loads(re.sub(r\"'\", '\"', s))\n",
    "                labels = [str(t).strip() for t in obj]\n",
    "            except Exception:\n",
    "                labels = []\n",
    "\n",
    "    # Fallback split\n",
    "    if not labels:\n",
    "        parts = re.split(r\"[,\\n;|]+\", s)\n",
    "        labels = []\n",
    "        for t in parts:\n",
    "            t = re.sub(r\"^tags?\\s*:\\s*\", \"\", t.strip(), flags=re.IGNORECASE)\n",
    "            if t:\n",
    "                labels.append(t)\n",
    "\n",
    "    # Normalize + keep only known labels\n",
    "    out = []\n",
    "    for t in labels:\n",
    "        canon = normalize_label(t)\n",
    "        if canon is not None:\n",
    "            out.append(canon)\n",
    "\n",
    "    # de-dup while preserving order\n",
    "    seen = set()\n",
    "    out2 = []\n",
    "    for t in out:\n",
    "        if t not in seen:\n",
    "            seen.add(t)\n",
    "            out2.append(t)\n",
    "    return out2\n",
    "\n",
    "# ====== 4) BUILD y_true / y_pred ======\n",
    "assert \"Tags\" in df.columns, \"Missing ground-truth column: Tags\"\n",
    "assert \"predicted_labels_yes\" in df.columns, \"Missing prediction column: predicted_labels_yes\"\n",
    "\n",
    "y_true_list_all = df[\"Tags\"].apply(parse_labels).tolist()\n",
    "y_pred_list_all = df[\"predicted_labels_yes\"].apply(parse_labels).tolist()\n",
    "\n",
    "print(\"\\nEmpty ground-truth rows:\", sum(len(x) == 0 for x in y_true_list_all))\n",
    "print(\"Empty prediction rows:\", sum(len(x) == 0 for x in y_pred_list_all))\n",
    "\n",
    "# --- Filter OUT excluded labels at the list level (optional but keeps things clean)\n",
    "def drop_excluded(labels):\n",
    "    return [t for t in labels if t not in EXCLUDE_LABELS]\n",
    "\n",
    "y_true_list = [drop_excluded(x) for x in y_true_list_all]\n",
    "y_pred_list = [drop_excluded(x) for x in y_pred_list_all]\n",
    "\n",
    "# Binarize ONLY over evaluation labels\n",
    "mlb = MultiLabelBinarizer(classes=EVAL_LABELS)\n",
    "Y_true = mlb.fit_transform(y_true_list)\n",
    "Y_pred = mlb.transform(y_pred_list)\n",
    "\n",
    "print(\"\\nEvaluating on labels (excluded: Not applicable, Seeking support):\")\n",
    "print(mlb.classes_)\n",
    "\n",
    "# ====== 5) OVERALL METRICS ======\n",
    "scores = {\n",
    "    \"micro_precision\": precision_score(Y_true, Y_pred, average=\"micro\", zero_division=0),\n",
    "    \"micro_recall\":    recall_score(Y_true, Y_pred, average=\"micro\", zero_division=0),\n",
    "    \"micro_f1\":        f1_score(Y_true, Y_pred, average=\"micro\", zero_division=0),\n",
    "\n",
    "    \"macro_precision\": precision_score(Y_true, Y_pred, average=\"macro\", zero_division=0),\n",
    "    \"macro_recall\":    recall_score(Y_true, Y_pred, average=\"macro\", zero_division=0),\n",
    "    \"macro_f1\":        f1_score(Y_true, Y_pred, average=\"macro\", zero_division=0),\n",
    "\n",
    "    \"samples_precision\": precision_score(Y_true, Y_pred, average=\"samples\", zero_division=0),\n",
    "    \"samples_recall\":    recall_score(Y_true, Y_pred, average=\"samples\", zero_division=0),\n",
    "    \"samples_f1\":        f1_score(Y_true, Y_pred, average=\"samples\", zero_division=0),\n",
    "}\n",
    "\n",
    "print(\"\\nOverall Precision \\\\& Recall \\\\& F1 (EXCLUDING Not applicable + Seeking support)\")\n",
    "for k, v in scores.items():\n",
    "    print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "# ====== 6) PER-LABEL METRICS ======\n",
    "p, r, f1, support = precision_recall_fscore_support(\n",
    "    Y_true, Y_pred, average=None, zero_division=0\n",
    ")\n",
    "\n",
    "per_label_df = pd.DataFrame({\n",
    "    \"label\": mlb.classes_,\n",
    "    \"precision\": p,\n",
    "    \"recall\": r,\n",
    "    \"f1\": f1,\n",
    "    \"support_true\": support\n",
    "}).sort_values(\"f1\", ascending=False)\n",
    "\n",
    "print(\"\\nPer-label metrics (excluded labels removed):\")\n",
    "display(per_label_df)\n",
    "\n",
    "print(\"\\nClassification report (excluded labels removed):\")\n",
    "print(classification_report(Y_true, Y_pred, target_names=mlb.classes_, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "61f1ad7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: valid_with_predictions_goss_v44.csv\n",
      "Rows: 44\n",
      "Columns: ['post_id', 'parent_id', 'subreddit', 'comment_id', 'parent_fullname', 'depth', 'comment_author', 'comment_body', 'comment_score', 'created_utc', 'permalink', 'is_post_author', 'title', 'author', 'body', 'prompt', 'Tags', 'is_ambivalent_sa_domain', 'op_author', 'last_comment_depth', 'last_comment_author', 'is_last_comment_by_op', 'llm_error', 'predicted_labels_yes', 'gate_used', 'Information support', 'Emotional support', 'Esteem support', 'Network support', 'Tangible assistance', 'Seeking support', 'Group interactions', 'Not applicable']\n",
      "\n",
      "Empty ground-truth rows: 0\n",
      "Empty prediction rows: 0\n",
      "\n",
      "Evaluating on labels (excluded: Not applicable, Seeking support):\n",
      "['Information support' 'Emotional support' 'Esteem support'\n",
      " 'Network support' 'Tangible assistance' 'Group interactions']\n",
      "\n",
      "Overall Precision \\& Recall \\& F1 (EXCLUDING Not applicable + Seeking support)\n",
      "micro_precision: 0.8833\n",
      "micro_recall: 0.7361\n",
      "micro_f1: 0.8030\n",
      "macro_precision: 0.8726\n",
      "macro_recall: 0.7187\n",
      "macro_f1: 0.7750\n",
      "samples_precision: 0.7008\n",
      "samples_recall: 0.6375\n",
      "samples_f1: 0.6548\n",
      "\n",
      "Per-label metrics (excluded labels removed):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>support_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tangible assistance</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Information support</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.931034</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Emotional support</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.896552</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Network support</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Group interactions</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Esteem support</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 label  precision    recall        f1  support_true\n",
       "4  Tangible assistance   1.000000  1.000000  1.000000             2\n",
       "0  Information support   0.964286  0.931034  0.947368            29\n",
       "1    Emotional support   0.866667  0.928571  0.896552            14\n",
       "3      Network support   1.000000  0.666667  0.800000             3\n",
       "5   Group interactions   0.833333  0.500000  0.625000            10\n",
       "2       Esteem support   0.571429  0.285714  0.380952            14"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report (excluded labels removed):\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "Information support       0.96      0.93      0.95        29\n",
      "  Emotional support       0.87      0.93      0.90        14\n",
      "     Esteem support       0.57      0.29      0.38        14\n",
      "    Network support       1.00      0.67      0.80         3\n",
      "Tangible assistance       1.00      1.00      1.00         2\n",
      " Group interactions       0.83      0.50      0.62        10\n",
      "\n",
      "          micro avg       0.88      0.74      0.80        72\n",
      "          macro avg       0.87      0.72      0.77        72\n",
      "       weighted avg       0.85      0.74      0.78        72\n",
      "        samples avg       0.70      0.64      0.65        72\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import (\n",
    "    precision_score, recall_score, f1_score,\n",
    "    classification_report, precision_recall_fscore_support\n",
    ")\n",
    "\n",
    "# ====== 1) LOAD YOUR FILE ======\n",
    "IN_PATH = \"valid_with_predictions_goss_v44.csv\"\n",
    "df = pd.read_csv(IN_PATH)\n",
    "\n",
    "print(\"Loaded:\", IN_PATH)\n",
    "print(\"Rows:\", len(df))\n",
    "print(\"Columns:\", list(df.columns))\n",
    "\n",
    "# ====== 2) LABEL SET ======\n",
    "ALL_LABELS = [\n",
    "    \"Information support\",\n",
    "    \"Emotional support\",\n",
    "    \"Esteem support\",\n",
    "    \"Network support\",\n",
    "    \"Tangible assistance\",\n",
    "    \"Seeking support\",\n",
    "    \"Group interactions\",\n",
    "    \"Not applicable\",\n",
    "]\n",
    "\n",
    "EXCLUDE_LABELS = {\"Not applicable\", \"Seeking support\"}\n",
    "EVAL_LABELS = [lab for lab in ALL_LABELS if lab not in EXCLUDE_LABELS]\n",
    "\n",
    "# map for case/spacing normalization\n",
    "_norm_map = {lab.lower().strip(): lab for lab in ALL_LABELS}\n",
    "\n",
    "def normalize_label(t: str):\n",
    "    t2 = str(t).strip()\n",
    "    if not t2:\n",
    "        return None\n",
    "    key = t2.lower().strip()\n",
    "    return _norm_map.get(key, None)  # canonical label or None if unknown\n",
    "\n",
    "# ====== 3) PARSE TAG STRINGS ======\n",
    "def parse_labels(x):\n",
    "    if x is None or (isinstance(x, float) and np.isnan(x)):\n",
    "        return []\n",
    "    s = str(x).strip()\n",
    "    if s == \"\" or s.lower() in {\"nan\", \"none\"}:\n",
    "        return []\n",
    "\n",
    "    labels = []\n",
    "\n",
    "    # Try JSON list\n",
    "    if s.startswith(\"[\") and s.endswith(\"]\"):\n",
    "        try:\n",
    "            obj = json.loads(s)\n",
    "            labels = [str(t).strip() for t in obj]\n",
    "        except Exception:\n",
    "            try:\n",
    "                obj = json.loads(re.sub(r\"'\", '\"', s))\n",
    "                labels = [str(t).strip() for t in obj]\n",
    "            except Exception:\n",
    "                labels = []\n",
    "\n",
    "    # Fallback split\n",
    "    if not labels:\n",
    "        parts = re.split(r\"[,\\n;|]+\", s)\n",
    "        labels = []\n",
    "        for t in parts:\n",
    "            t = re.sub(r\"^tags?\\s*:\\s*\", \"\", t.strip(), flags=re.IGNORECASE)\n",
    "            if t:\n",
    "                labels.append(t)\n",
    "\n",
    "    # Normalize + keep only known labels\n",
    "    out = []\n",
    "    for t in labels:\n",
    "        canon = normalize_label(t)\n",
    "        if canon is not None:\n",
    "            out.append(canon)\n",
    "\n",
    "    # de-dup while preserving order\n",
    "    seen = set()\n",
    "    out2 = []\n",
    "    for t in out:\n",
    "        if t not in seen:\n",
    "            seen.add(t)\n",
    "            out2.append(t)\n",
    "    return out2\n",
    "\n",
    "# ====== 4) BUILD y_true / y_pred ======\n",
    "assert \"Tags\" in df.columns, \"Missing ground-truth column: Tags\"\n",
    "assert \"predicted_labels_yes\" in df.columns, \"Missing prediction column: predicted_labels_yes\"\n",
    "\n",
    "y_true_list_all = df[\"Tags\"].apply(parse_labels).tolist()\n",
    "y_pred_list_all = df[\"predicted_labels_yes\"].apply(parse_labels).tolist()\n",
    "\n",
    "print(\"\\nEmpty ground-truth rows:\", sum(len(x) == 0 for x in y_true_list_all))\n",
    "print(\"Empty prediction rows:\", sum(len(x) == 0 for x in y_pred_list_all))\n",
    "\n",
    "# --- Filter OUT excluded labels at the list level (optional but keeps things clean)\n",
    "def drop_excluded(labels):\n",
    "    return [t for t in labels if t not in EXCLUDE_LABELS]\n",
    "\n",
    "y_true_list = [drop_excluded(x) for x in y_true_list_all]\n",
    "y_pred_list = [drop_excluded(x) for x in y_pred_list_all]\n",
    "\n",
    "# Binarize ONLY over evaluation labels\n",
    "mlb = MultiLabelBinarizer(classes=EVAL_LABELS)\n",
    "Y_true = mlb.fit_transform(y_true_list)\n",
    "Y_pred = mlb.transform(y_pred_list)\n",
    "\n",
    "print(\"\\nEvaluating on labels (excluded: Not applicable, Seeking support):\")\n",
    "print(mlb.classes_)\n",
    "\n",
    "# ====== 5) OVERALL METRICS ======\n",
    "scores = {\n",
    "    \"micro_precision\": precision_score(Y_true, Y_pred, average=\"micro\", zero_division=0),\n",
    "    \"micro_recall\":    recall_score(Y_true, Y_pred, average=\"micro\", zero_division=0),\n",
    "    \"micro_f1\":        f1_score(Y_true, Y_pred, average=\"micro\", zero_division=0),\n",
    "\n",
    "    \"macro_precision\": precision_score(Y_true, Y_pred, average=\"macro\", zero_division=0),\n",
    "    \"macro_recall\":    recall_score(Y_true, Y_pred, average=\"macro\", zero_division=0),\n",
    "    \"macro_f1\":        f1_score(Y_true, Y_pred, average=\"macro\", zero_division=0),\n",
    "\n",
    "    \"samples_precision\": precision_score(Y_true, Y_pred, average=\"samples\", zero_division=0),\n",
    "    \"samples_recall\":    recall_score(Y_true, Y_pred, average=\"samples\", zero_division=0),\n",
    "    \"samples_f1\":        f1_score(Y_true, Y_pred, average=\"samples\", zero_division=0),\n",
    "}\n",
    "\n",
    "print(\"\\nOverall Precision \\\\& Recall \\\\& F1 (EXCLUDING Not applicable + Seeking support)\")\n",
    "for k, v in scores.items():\n",
    "    print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "# ====== 6) PER-LABEL METRICS ======\n",
    "p, r, f1, support = precision_recall_fscore_support(\n",
    "    Y_true, Y_pred, average=None, zero_division=0\n",
    ")\n",
    "\n",
    "per_label_df = pd.DataFrame({\n",
    "    \"label\": mlb.classes_,\n",
    "    \"precision\": p,\n",
    "    \"recall\": r,\n",
    "    \"f1\": f1,\n",
    "    \"support_true\": support\n",
    "}).sort_values(\"f1\", ascending=False)\n",
    "\n",
    "print(\"\\nPer-label metrics (excluded labels removed):\")\n",
    "display(per_label_df)\n",
    "\n",
    "print(\"\\nClassification report (excluded labels removed):\")\n",
    "print(classification_report(Y_true, Y_pred, target_names=mlb.classes_, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f2feb824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: valid_with_predictions_4mini.csv\n",
      "Rows: 86\n",
      "Columns: ['post_id', 'parent_id', 'subreddit', 'comment_id', 'parent_fullname', 'depth', 'comment_author', 'comment_body', 'comment_score', 'created_utc', 'permalink', 'is_post_author', 'title', 'author', 'body', 'prompt', 'Tags', 'is_ambivalent_sa_domain', 'op_author', 'last_comment_depth', 'last_comment_author', 'is_last_comment_by_op', 'llm_error', 'predicted_labels_yes', 'gate_used', 'Information support', 'Emotional support', 'Esteem support', 'Network support', 'Tangible assistance', 'Seeking support', 'Group interactions', 'Not applicable']\n",
      "\n",
      "Empty ground-truth rows: 0\n",
      "Empty prediction rows: 2\n",
      "\n",
      "Evaluating on labels (excluded: Not applicable, Seeking support):\n",
      "['Information support' 'Emotional support' 'Esteem support'\n",
      " 'Network support' 'Tangible assistance' 'Group interactions']\n",
      "\n",
      "Overall Precision \\& Recall \\& F1 (EXCLUDING Not applicable + Seeking support)\n",
      "micro_precision: 0.8333\n",
      "micro_recall: 0.7634\n",
      "micro_f1: 0.7968\n",
      "macro_precision: 0.8264\n",
      "macro_recall: 0.7931\n",
      "macro_f1: 0.8057\n",
      "samples_precision: 0.6246\n",
      "samples_recall: 0.5965\n",
      "samples_f1: 0.5986\n",
      "\n",
      "Per-label metrics (excluded labels removed):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>support_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tangible assistance</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Emotional support</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.872727</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Information support</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Network support</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Group interactions</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.744186</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Esteem support</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 label  precision    recall        f1  support_true\n",
       "4  Tangible assistance   1.000000  1.000000  1.000000             2\n",
       "1    Emotional support   0.857143  0.888889  0.872727            27\n",
       "0  Information support   0.933333  0.777778  0.848485            54\n",
       "3      Network support   0.750000  0.750000  0.750000             4\n",
       "5   Group interactions   0.695652  0.800000  0.744186            20\n",
       "2       Esteem support   0.722222  0.541667  0.619048            24"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report (excluded labels removed):\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "Information support       0.93      0.78      0.85        54\n",
      "  Emotional support       0.86      0.89      0.87        27\n",
      "     Esteem support       0.72      0.54      0.62        24\n",
      "    Network support       0.75      0.75      0.75         4\n",
      "Tangible assistance       1.00      1.00      1.00         2\n",
      " Group interactions       0.70      0.80      0.74        20\n",
      "\n",
      "          micro avg       0.83      0.76      0.80       131\n",
      "          macro avg       0.83      0.79      0.81       131\n",
      "       weighted avg       0.84      0.76      0.79       131\n",
      "        samples avg       0.62      0.60      0.60       131\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import (\n",
    "    precision_score, recall_score, f1_score,\n",
    "    classification_report, precision_recall_fscore_support\n",
    ")\n",
    "\n",
    "# ====== 1) LOAD YOUR FILE ======\n",
    "IN_PATH = \"valid_with_predictions_4mini.csv\"\n",
    "df = pd.read_csv(IN_PATH)\n",
    "\n",
    "print(\"Loaded:\", IN_PATH)\n",
    "print(\"Rows:\", len(df))\n",
    "print(\"Columns:\", list(df.columns))\n",
    "\n",
    "# ====== 2) LABEL SET ======\n",
    "ALL_LABELS = [\n",
    "    \"Information support\",\n",
    "    \"Emotional support\",\n",
    "    \"Esteem support\",\n",
    "    \"Network support\",\n",
    "    \"Tangible assistance\",\n",
    "    \"Seeking support\",\n",
    "    \"Group interactions\",\n",
    "    \"Not applicable\",\n",
    "]\n",
    "\n",
    "EXCLUDE_LABELS = {\"Not applicable\", \"Seeking support\"}\n",
    "EVAL_LABELS = [lab for lab in ALL_LABELS if lab not in EXCLUDE_LABELS]\n",
    "\n",
    "# map for case/spacing normalization\n",
    "_norm_map = {lab.lower().strip(): lab for lab in ALL_LABELS}\n",
    "\n",
    "def normalize_label(t: str):\n",
    "    t2 = str(t).strip()\n",
    "    if not t2:\n",
    "        return None\n",
    "    key = t2.lower().strip()\n",
    "    return _norm_map.get(key, None)  # canonical label or None if unknown\n",
    "\n",
    "# ====== 3) PARSE TAG STRINGS ======\n",
    "def parse_labels(x):\n",
    "    if x is None or (isinstance(x, float) and np.isnan(x)):\n",
    "        return []\n",
    "    s = str(x).strip()\n",
    "    if s == \"\" or s.lower() in {\"nan\", \"none\"}:\n",
    "        return []\n",
    "\n",
    "    labels = []\n",
    "\n",
    "    # Try JSON list\n",
    "    if s.startswith(\"[\") and s.endswith(\"]\"):\n",
    "        try:\n",
    "            obj = json.loads(s)\n",
    "            labels = [str(t).strip() for t in obj]\n",
    "        except Exception:\n",
    "            try:\n",
    "                obj = json.loads(re.sub(r\"'\", '\"', s))\n",
    "                labels = [str(t).strip() for t in obj]\n",
    "            except Exception:\n",
    "                labels = []\n",
    "\n",
    "    # Fallback split\n",
    "    if not labels:\n",
    "        parts = re.split(r\"[,\\n;|]+\", s)\n",
    "        labels = []\n",
    "        for t in parts:\n",
    "            t = re.sub(r\"^tags?\\s*:\\s*\", \"\", t.strip(), flags=re.IGNORECASE)\n",
    "            if t:\n",
    "                labels.append(t)\n",
    "\n",
    "    # Normalize + keep only known labels\n",
    "    out = []\n",
    "    for t in labels:\n",
    "        canon = normalize_label(t)\n",
    "        if canon is not None:\n",
    "            out.append(canon)\n",
    "\n",
    "    # de-dup while preserving order\n",
    "    seen = set()\n",
    "    out2 = []\n",
    "    for t in out:\n",
    "        if t not in seen:\n",
    "            seen.add(t)\n",
    "            out2.append(t)\n",
    "    return out2\n",
    "\n",
    "# ====== 4) BUILD y_true / y_pred ======\n",
    "assert \"Tags\" in df.columns, \"Missing ground-truth column: Tags\"\n",
    "assert \"predicted_labels_yes\" in df.columns, \"Missing prediction column: predicted_labels_yes\"\n",
    "\n",
    "y_true_list_all = df[\"Tags\"].apply(parse_labels).tolist()\n",
    "y_pred_list_all = df[\"predicted_labels_yes\"].apply(parse_labels).tolist()\n",
    "\n",
    "print(\"\\nEmpty ground-truth rows:\", sum(len(x) == 0 for x in y_true_list_all))\n",
    "print(\"Empty prediction rows:\", sum(len(x) == 0 for x in y_pred_list_all))\n",
    "\n",
    "# --- Filter OUT excluded labels at the list level (optional but keeps things clean)\n",
    "def drop_excluded(labels):\n",
    "    return [t for t in labels if t not in EXCLUDE_LABELS]\n",
    "\n",
    "y_true_list = [drop_excluded(x) for x in y_true_list_all]\n",
    "y_pred_list = [drop_excluded(x) for x in y_pred_list_all]\n",
    "\n",
    "# Binarize ONLY over evaluation labels\n",
    "mlb = MultiLabelBinarizer(classes=EVAL_LABELS)\n",
    "Y_true = mlb.fit_transform(y_true_list)\n",
    "Y_pred = mlb.transform(y_pred_list)\n",
    "\n",
    "print(\"\\nEvaluating on labels (excluded: Not applicable, Seeking support):\")\n",
    "print(mlb.classes_)\n",
    "\n",
    "# ====== 5) OVERALL METRICS ======\n",
    "scores = {\n",
    "    \"micro_precision\": precision_score(Y_true, Y_pred, average=\"micro\", zero_division=0),\n",
    "    \"micro_recall\":    recall_score(Y_true, Y_pred, average=\"micro\", zero_division=0),\n",
    "    \"micro_f1\":        f1_score(Y_true, Y_pred, average=\"micro\", zero_division=0),\n",
    "\n",
    "    \"macro_precision\": precision_score(Y_true, Y_pred, average=\"macro\", zero_division=0),\n",
    "    \"macro_recall\":    recall_score(Y_true, Y_pred, average=\"macro\", zero_division=0),\n",
    "    \"macro_f1\":        f1_score(Y_true, Y_pred, average=\"macro\", zero_division=0),\n",
    "\n",
    "    \"samples_precision\": precision_score(Y_true, Y_pred, average=\"samples\", zero_division=0),\n",
    "    \"samples_recall\":    recall_score(Y_true, Y_pred, average=\"samples\", zero_division=0),\n",
    "    \"samples_f1\":        f1_score(Y_true, Y_pred, average=\"samples\", zero_division=0),\n",
    "}\n",
    "\n",
    "print(\"\\nOverall Precision \\\\& Recall \\\\& F1 (EXCLUDING Not applicable + Seeking support)\")\n",
    "for k, v in scores.items():\n",
    "    print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "# ====== 6) PER-LABEL METRICS ======\n",
    "p, r, f1, support = precision_recall_fscore_support(\n",
    "    Y_true, Y_pred, average=None, zero_division=0\n",
    ")\n",
    "\n",
    "per_label_df = pd.DataFrame({\n",
    "    \"label\": mlb.classes_,\n",
    "    \"precision\": p,\n",
    "    \"recall\": r,\n",
    "    \"f1\": f1,\n",
    "    \"support_true\": support\n",
    "}).sort_values(\"f1\", ascending=False)\n",
    "\n",
    "print(\"\\nPer-label metrics (excluded labels removed):\")\n",
    "display(per_label_df)\n",
    "\n",
    "print(\"\\nClassification report (excluded labels removed):\")\n",
    "print(classification_report(Y_true, Y_pred, target_names=mlb.classes_, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "724ac32f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: valid_with_predictions_4mini_v44.csv\n",
      "Rows: 44\n",
      "Columns: ['post_id', 'parent_id', 'subreddit', 'comment_id', 'parent_fullname', 'depth', 'comment_author', 'comment_body', 'comment_score', 'created_utc', 'permalink', 'is_post_author', 'title', 'author', 'body', 'prompt', 'Tags', 'is_ambivalent_sa_domain', 'op_author', 'last_comment_depth', 'last_comment_author', 'is_last_comment_by_op', 'llm_error', 'predicted_labels_yes', 'gate_used', 'Information support', 'Emotional support', 'Esteem support', 'Network support', 'Tangible assistance', 'Seeking support', 'Group interactions', 'Not applicable']\n",
      "\n",
      "Empty ground-truth rows: 0\n",
      "Empty prediction rows: 0\n",
      "\n",
      "Evaluating on labels (excluded: Not applicable, Seeking support):\n",
      "['Information support' 'Emotional support' 'Esteem support'\n",
      " 'Network support' 'Tangible assistance' 'Group interactions']\n",
      "\n",
      "Overall Precision \\& Recall \\& F1 (EXCLUDING Not applicable + Seeking support)\n",
      "micro_precision: 0.7941\n",
      "micro_recall: 0.7500\n",
      "micro_f1: 0.7714\n",
      "macro_precision: 0.8220\n",
      "macro_recall: 0.7524\n",
      "macro_f1: 0.7778\n",
      "samples_precision: 0.6439\n",
      "samples_recall: 0.6186\n",
      "samples_f1: 0.6117\n",
      "\n",
      "Per-label metrics (excluded labels removed):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>support_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tangible assistance</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Information support</td>\n",
       "      <td>0.925926</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Network support</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Emotional support</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Group interactions</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Esteem support</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 label  precision    recall        f1  support_true\n",
       "4  Tangible assistance   1.000000  1.000000  1.000000             2\n",
       "0  Information support   0.925926  0.862069  0.892857            29\n",
       "3      Network support   1.000000  0.666667  0.800000             3\n",
       "1    Emotional support   0.705882  0.857143  0.774194            14\n",
       "5   Group interactions   0.700000  0.700000  0.700000            10\n",
       "2       Esteem support   0.600000  0.428571  0.500000            14"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report (excluded labels removed):\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "Information support       0.93      0.86      0.89        29\n",
      "  Emotional support       0.71      0.86      0.77        14\n",
      "     Esteem support       0.60      0.43      0.50        14\n",
      "    Network support       1.00      0.67      0.80         3\n",
      "Tangible assistance       1.00      1.00      1.00         2\n",
      " Group interactions       0.70      0.70      0.70        10\n",
      "\n",
      "          micro avg       0.79      0.75      0.77        72\n",
      "          macro avg       0.82      0.75      0.78        72\n",
      "       weighted avg       0.79      0.75      0.77        72\n",
      "        samples avg       0.64      0.62      0.61        72\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import (\n",
    "    precision_score, recall_score, f1_score,\n",
    "    classification_report, precision_recall_fscore_support\n",
    ")\n",
    "\n",
    "# ====== 1) LOAD YOUR FILE ======\n",
    "IN_PATH = \"valid_with_predictions_4mini_v44.csv\"\n",
    "df = pd.read_csv(IN_PATH)\n",
    "\n",
    "print(\"Loaded:\", IN_PATH)\n",
    "print(\"Rows:\", len(df))\n",
    "print(\"Columns:\", list(df.columns))\n",
    "\n",
    "# ====== 2) LABEL SET ======\n",
    "ALL_LABELS = [\n",
    "    \"Information support\",\n",
    "    \"Emotional support\",\n",
    "    \"Esteem support\",\n",
    "    \"Network support\",\n",
    "    \"Tangible assistance\",\n",
    "    \"Seeking support\",\n",
    "    \"Group interactions\",\n",
    "    \"Not applicable\",\n",
    "]\n",
    "\n",
    "EXCLUDE_LABELS = {\"Not applicable\", \"Seeking support\"}\n",
    "EVAL_LABELS = [lab for lab in ALL_LABELS if lab not in EXCLUDE_LABELS]\n",
    "\n",
    "# map for case/spacing normalization\n",
    "_norm_map = {lab.lower().strip(): lab for lab in ALL_LABELS}\n",
    "\n",
    "def normalize_label(t: str):\n",
    "    t2 = str(t).strip()\n",
    "    if not t2:\n",
    "        return None\n",
    "    key = t2.lower().strip()\n",
    "    return _norm_map.get(key, None)  # canonical label or None if unknown\n",
    "\n",
    "# ====== 3) PARSE TAG STRINGS ======\n",
    "def parse_labels(x):\n",
    "    if x is None or (isinstance(x, float) and np.isnan(x)):\n",
    "        return []\n",
    "    s = str(x).strip()\n",
    "    if s == \"\" or s.lower() in {\"nan\", \"none\"}:\n",
    "        return []\n",
    "\n",
    "    labels = []\n",
    "\n",
    "    # Try JSON list\n",
    "    if s.startswith(\"[\") and s.endswith(\"]\"):\n",
    "        try:\n",
    "            obj = json.loads(s)\n",
    "            labels = [str(t).strip() for t in obj]\n",
    "        except Exception:\n",
    "            try:\n",
    "                obj = json.loads(re.sub(r\"'\", '\"', s))\n",
    "                labels = [str(t).strip() for t in obj]\n",
    "            except Exception:\n",
    "                labels = []\n",
    "\n",
    "    # Fallback split\n",
    "    if not labels:\n",
    "        parts = re.split(r\"[,\\n;|]+\", s)\n",
    "        labels = []\n",
    "        for t in parts:\n",
    "            t = re.sub(r\"^tags?\\s*:\\s*\", \"\", t.strip(), flags=re.IGNORECASE)\n",
    "            if t:\n",
    "                labels.append(t)\n",
    "\n",
    "    # Normalize + keep only known labels\n",
    "    out = []\n",
    "    for t in labels:\n",
    "        canon = normalize_label(t)\n",
    "        if canon is not None:\n",
    "            out.append(canon)\n",
    "\n",
    "    # de-dup while preserving order\n",
    "    seen = set()\n",
    "    out2 = []\n",
    "    for t in out:\n",
    "        if t not in seen:\n",
    "            seen.add(t)\n",
    "            out2.append(t)\n",
    "    return out2\n",
    "\n",
    "# ====== 4) BUILD y_true / y_pred ======\n",
    "assert \"Tags\" in df.columns, \"Missing ground-truth column: Tags\"\n",
    "assert \"predicted_labels_yes\" in df.columns, \"Missing prediction column: predicted_labels_yes\"\n",
    "\n",
    "y_true_list_all = df[\"Tags\"].apply(parse_labels).tolist()\n",
    "y_pred_list_all = df[\"predicted_labels_yes\"].apply(parse_labels).tolist()\n",
    "\n",
    "print(\"\\nEmpty ground-truth rows:\", sum(len(x) == 0 for x in y_true_list_all))\n",
    "print(\"Empty prediction rows:\", sum(len(x) == 0 for x in y_pred_list_all))\n",
    "\n",
    "# --- Filter OUT excluded labels at the list level (optional but keeps things clean)\n",
    "def drop_excluded(labels):\n",
    "    return [t for t in labels if t not in EXCLUDE_LABELS]\n",
    "\n",
    "y_true_list = [drop_excluded(x) for x in y_true_list_all]\n",
    "y_pred_list = [drop_excluded(x) for x in y_pred_list_all]\n",
    "\n",
    "# Binarize ONLY over evaluation labels\n",
    "mlb = MultiLabelBinarizer(classes=EVAL_LABELS)\n",
    "Y_true = mlb.fit_transform(y_true_list)\n",
    "Y_pred = mlb.transform(y_pred_list)\n",
    "\n",
    "print(\"\\nEvaluating on labels (excluded: Not applicable, Seeking support):\")\n",
    "print(mlb.classes_)\n",
    "\n",
    "# ====== 5) OVERALL METRICS ======\n",
    "scores = {\n",
    "    \"micro_precision\": precision_score(Y_true, Y_pred, average=\"micro\", zero_division=0),\n",
    "    \"micro_recall\":    recall_score(Y_true, Y_pred, average=\"micro\", zero_division=0),\n",
    "    \"micro_f1\":        f1_score(Y_true, Y_pred, average=\"micro\", zero_division=0),\n",
    "\n",
    "    \"macro_precision\": precision_score(Y_true, Y_pred, average=\"macro\", zero_division=0),\n",
    "    \"macro_recall\":    recall_score(Y_true, Y_pred, average=\"macro\", zero_division=0),\n",
    "    \"macro_f1\":        f1_score(Y_true, Y_pred, average=\"macro\", zero_division=0),\n",
    "\n",
    "    \"samples_precision\": precision_score(Y_true, Y_pred, average=\"samples\", zero_division=0),\n",
    "    \"samples_recall\":    recall_score(Y_true, Y_pred, average=\"samples\", zero_division=0),\n",
    "    \"samples_f1\":        f1_score(Y_true, Y_pred, average=\"samples\", zero_division=0),\n",
    "}\n",
    "\n",
    "print(\"\\nOverall Precision \\\\& Recall \\\\& F1 (EXCLUDING Not applicable + Seeking support)\")\n",
    "for k, v in scores.items():\n",
    "    print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "# ====== 6) PER-LABEL METRICS ======\n",
    "p, r, f1, support = precision_recall_fscore_support(\n",
    "    Y_true, Y_pred, average=None, zero_division=0\n",
    ")\n",
    "\n",
    "per_label_df = pd.DataFrame({\n",
    "    \"label\": mlb.classes_,\n",
    "    \"precision\": p,\n",
    "    \"recall\": r,\n",
    "    \"f1\": f1,\n",
    "    \"support_true\": support\n",
    "}).sort_values(\"f1\", ascending=False)\n",
    "\n",
    "print(\"\\nPer-label metrics (excluded labels removed):\")\n",
    "display(per_label_df)\n",
    "\n",
    "print(\"\\nClassification report (excluded labels removed):\")\n",
    "print(classification_report(Y_true, Y_pred, target_names=mlb.classes_, zero_division=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "225f47ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: test_with_predictions_4mini_t44.csv\n",
      "Rows: 44\n",
      "Columns: ['post_id', 'parent_id', 'subreddit', 'comment_id', 'parent_fullname', 'depth', 'comment_author', 'comment_body', 'comment_score', 'created_utc', 'permalink', 'is_post_author', 'title', 'author', 'body', 'prompt', 'Tags', 'is_ambivalent_sa_domain', 'op_author', 'last_comment_depth', 'last_comment_author', 'is_last_comment_by_op', 'llm_error', 'predicted_labels_yes', 'gate_used', 'Information support', 'Emotional support', 'Esteem support', 'Network support', 'Tangible assistance', 'Seeking support', 'Group interactions', 'Not applicable']\n",
      "\n",
      "Empty ground-truth rows: 0\n",
      "Empty prediction rows: 2\n",
      "\n",
      "Evaluating on labels (excluded: Not applicable, Seeking support):\n",
      "['Information support' 'Emotional support' 'Esteem support'\n",
      " 'Network support' 'Tangible assistance' 'Group interactions']\n",
      "\n",
      "Overall Precision \\& Recall \\& F1 (EXCLUDING Not applicable + Seeking support)\n",
      "micro_precision: 0.7302\n",
      "micro_recall: 0.7797\n",
      "micro_f1: 0.7541\n",
      "macro_precision: 0.6417\n",
      "macro_recall: 0.6905\n",
      "macro_f1: 0.6572\n",
      "samples_precision: 0.5227\n",
      "samples_recall: 0.5284\n",
      "samples_f1: 0.5214\n",
      "\n",
      "Per-label metrics (excluded labels removed):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>support_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Network support</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Emotional support</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Information support</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Esteem support</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Group interactions</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tangible assistance</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 label  precision    recall        f1  support_true\n",
       "3      Network support       1.00  1.000000  1.000000             1\n",
       "1    Emotional support       0.75  0.923077  0.827586            13\n",
       "0  Information support       0.90  0.720000  0.800000            25\n",
       "2       Esteem support       0.70  0.700000  0.700000            10\n",
       "5   Group interactions       0.50  0.800000  0.615385            10\n",
       "4  Tangible assistance       0.00  0.000000  0.000000             0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report (excluded labels removed):\n",
      "                     precision    recall  f1-score   support\n",
      "\n",
      "Information support       0.90      0.72      0.80        25\n",
      "  Emotional support       0.75      0.92      0.83        13\n",
      "     Esteem support       0.70      0.70      0.70        10\n",
      "    Network support       1.00      1.00      1.00         1\n",
      "Tangible assistance       0.00      0.00      0.00         0\n",
      " Group interactions       0.50      0.80      0.62        10\n",
      "\n",
      "          micro avg       0.73      0.78      0.75        59\n",
      "          macro avg       0.64      0.69      0.66        59\n",
      "       weighted avg       0.77      0.78      0.76        59\n",
      "        samples avg       0.52      0.53      0.52        59\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import (\n",
    "    precision_score, recall_score, f1_score,\n",
    "    classification_report, precision_recall_fscore_support\n",
    ")\n",
    "\n",
    "# ====== 1) LOAD YOUR FILE ======\n",
    "IN_PATH = \"test_with_predictions_4mini_t44.csv\"\n",
    "df = pd.read_csv(IN_PATH)\n",
    "\n",
    "print(\"Loaded:\", IN_PATH)\n",
    "print(\"Rows:\", len(df))\n",
    "print(\"Columns:\", list(df.columns))\n",
    "\n",
    "# ====== 2) LABEL SET ======\n",
    "ALL_LABELS = [\n",
    "    \"Information support\",\n",
    "    \"Emotional support\",\n",
    "    \"Esteem support\",\n",
    "    \"Network support\",\n",
    "    \"Tangible assistance\",\n",
    "    \"Seeking support\",\n",
    "    \"Group interactions\",\n",
    "    \"Not applicable\",\n",
    "]\n",
    "\n",
    "EXCLUDE_LABELS = {\"Not applicable\", \"Seeking support\"}\n",
    "EVAL_LABELS = [lab for lab in ALL_LABELS if lab not in EXCLUDE_LABELS]\n",
    "\n",
    "# map for case/spacing normalization\n",
    "_norm_map = {lab.lower().strip(): lab for lab in ALL_LABELS}\n",
    "\n",
    "def normalize_label(t: str):\n",
    "    t2 = str(t).strip()\n",
    "    if not t2:\n",
    "        return None\n",
    "    key = t2.lower().strip()\n",
    "    return _norm_map.get(key, None)  # canonical label or None if unknown\n",
    "\n",
    "# ====== 3) PARSE TAG STRINGS ======\n",
    "def parse_labels(x):\n",
    "    if x is None or (isinstance(x, float) and np.isnan(x)):\n",
    "        return []\n",
    "    s = str(x).strip()\n",
    "    if s == \"\" or s.lower() in {\"nan\", \"none\"}:\n",
    "        return []\n",
    "\n",
    "    labels = []\n",
    "\n",
    "    # Try JSON list\n",
    "    if s.startswith(\"[\") and s.endswith(\"]\"):\n",
    "        try:\n",
    "            obj = json.loads(s)\n",
    "            labels = [str(t).strip() for t in obj]\n",
    "        except Exception:\n",
    "            try:\n",
    "                obj = json.loads(re.sub(r\"'\", '\"', s))\n",
    "                labels = [str(t).strip() for t in obj]\n",
    "            except Exception:\n",
    "                labels = []\n",
    "\n",
    "    # Fallback split\n",
    "    if not labels:\n",
    "        parts = re.split(r\"[,\\n;|]+\", s)\n",
    "        labels = []\n",
    "        for t in parts:\n",
    "            t = re.sub(r\"^tags?\\s*:\\s*\", \"\", t.strip(), flags=re.IGNORECASE)\n",
    "            if t:\n",
    "                labels.append(t)\n",
    "\n",
    "    # Normalize + keep only known labels\n",
    "    out = []\n",
    "    for t in labels:\n",
    "        canon = normalize_label(t)\n",
    "        if canon is not None:\n",
    "            out.append(canon)\n",
    "\n",
    "    # de-dup while preserving order\n",
    "    seen = set()\n",
    "    out2 = []\n",
    "    for t in out:\n",
    "        if t not in seen:\n",
    "            seen.add(t)\n",
    "            out2.append(t)\n",
    "    return out2\n",
    "\n",
    "# ====== 4) BUILD y_true / y_pred ======\n",
    "assert \"Tags\" in df.columns, \"Missing ground-truth column: Tags\"\n",
    "assert \"predicted_labels_yes\" in df.columns, \"Missing prediction column: predicted_labels_yes\"\n",
    "\n",
    "y_true_list_all = df[\"Tags\"].apply(parse_labels).tolist()\n",
    "y_pred_list_all = df[\"predicted_labels_yes\"].apply(parse_labels).tolist()\n",
    "\n",
    "print(\"\\nEmpty ground-truth rows:\", sum(len(x) == 0 for x in y_true_list_all))\n",
    "print(\"Empty prediction rows:\", sum(len(x) == 0 for x in y_pred_list_all))\n",
    "\n",
    "# --- Filter OUT excluded labels at the list level (optional but keeps things clean)\n",
    "def drop_excluded(labels):\n",
    "    return [t for t in labels if t not in EXCLUDE_LABELS]\n",
    "\n",
    "y_true_list = [drop_excluded(x) for x in y_true_list_all]\n",
    "y_pred_list = [drop_excluded(x) for x in y_pred_list_all]\n",
    "\n",
    "# Binarize ONLY over evaluation labels\n",
    "mlb = MultiLabelBinarizer(classes=EVAL_LABELS)\n",
    "Y_true = mlb.fit_transform(y_true_list)\n",
    "Y_pred = mlb.transform(y_pred_list)\n",
    "\n",
    "print(\"\\nEvaluating on labels (excluded: Not applicable, Seeking support):\")\n",
    "print(mlb.classes_)\n",
    "\n",
    "# ====== 5) OVERALL METRICS ======\n",
    "scores = {\n",
    "    \"micro_precision\": precision_score(Y_true, Y_pred, average=\"micro\", zero_division=0),\n",
    "    \"micro_recall\":    recall_score(Y_true, Y_pred, average=\"micro\", zero_division=0),\n",
    "    \"micro_f1\":        f1_score(Y_true, Y_pred, average=\"micro\", zero_division=0),\n",
    "\n",
    "    \"macro_precision\": precision_score(Y_true, Y_pred, average=\"macro\", zero_division=0),\n",
    "    \"macro_recall\":    recall_score(Y_true, Y_pred, average=\"macro\", zero_division=0),\n",
    "    \"macro_f1\":        f1_score(Y_true, Y_pred, average=\"macro\", zero_division=0),\n",
    "\n",
    "    \"samples_precision\": precision_score(Y_true, Y_pred, average=\"samples\", zero_division=0),\n",
    "    \"samples_recall\":    recall_score(Y_true, Y_pred, average=\"samples\", zero_division=0),\n",
    "    \"samples_f1\":        f1_score(Y_true, Y_pred, average=\"samples\", zero_division=0),\n",
    "}\n",
    "\n",
    "print(\"\\nOverall Precision \\\\& Recall \\\\& F1 (EXCLUDING Not applicable + Seeking support)\")\n",
    "for k, v in scores.items():\n",
    "    print(f\"{k}: {v:.4f}\")\n",
    "\n",
    "# ====== 6) PER-LABEL METRICS ======\n",
    "p, r, f1, support = precision_recall_fscore_support(\n",
    "    Y_true, Y_pred, average=None, zero_division=0\n",
    ")\n",
    "\n",
    "per_label_df = pd.DataFrame({\n",
    "    \"label\": mlb.classes_,\n",
    "    \"precision\": p,\n",
    "    \"recall\": r,\n",
    "    \"f1\": f1,\n",
    "    \"support_true\": support\n",
    "}).sort_values(\"f1\", ascending=False)\n",
    "\n",
    "print(\"\\nPer-label metrics (excluded labels removed):\")\n",
    "display(per_label_df)\n",
    "\n",
    "print(\"\\nClassification report (excluded labels removed):\")\n",
    "print(classification_report(Y_true, Y_pred, target_names=mlb.classes_, zero_division=0))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
